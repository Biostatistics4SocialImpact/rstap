/*
    rstap is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    rstap is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with rstap.  If not, see <http://www.gnu.org/licenses/>.
*/
#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
#include <rstan/rstaninc.hpp>
// Code generated by Stan version 2.19.1

#include <stan/model/model_header.hpp>

namespace model_stap_bernoulli_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_stap_bernoulli");
    reader.add_event(2, 2, "include", "/functions/common_functions.stan");
    reader.add_event(2, 0, "start", "/functions/common_functions.stan");
    reader.add_event(398, 396, "end", "/functions/common_functions.stan");
    reader.add_event(398, 3, "restart", "model_stap_bernoulli");
    reader.add_event(398, 3, "include", "/functions/bernoulli_likelihoods.stan");
    reader.add_event(398, 0, "start", "/functions/bernoulli_likelihoods.stan");
    reader.add_event(525, 127, "end", "/functions/bernoulli_likelihoods.stan");
    reader.add_event(525, 4, "restart", "model_stap_bernoulli");
    reader.add_event(557, 36, "include", "/data/data_glm.stan");
    reader.add_event(557, 0, "start", "/data/data_glm.stan");
    reader.add_event(576, 19, "end", "/data/data_glm.stan");
    reader.add_event(576, 37, "restart", "model_stap_bernoulli");
    reader.add_event(590, 51, "include", "/data/hyperparameters.stan");
    reader.add_event(590, 0, "start", "/data/hyperparameters.stan");
    reader.add_event(613, 23, "end", "/data/hyperparameters.stan");
    reader.add_event(613, 52, "restart", "model_stap_bernoulli");
    reader.add_event(614, 53, "include", "/data/glmer_stuff.stan");
    reader.add_event(614, 0, "start", "/data/glmer_stuff.stan");
    reader.add_event(629, 15, "end", "/data/glmer_stuff.stan");
    reader.add_event(629, 54, "restart", "model_stap_bernoulli");
    reader.add_event(647, 72, "include", "/tdata/tdata_glm.stan");
    reader.add_event(647, 0, "start", "/tdata/tdata_glm.stan");
    reader.add_event(669, 22, "end", "/tdata/tdata_glm.stan");
    reader.add_event(669, 73, "restart", "model_stap_bernoulli");
    reader.add_event(673, 77, "include", "/parameters/parameters_glm.stan");
    reader.add_event(673, 0, "start", "/parameters/parameters_glm.stan");
    reader.add_event(688, 15, "end", "/parameters/parameters_glm.stan");
    reader.add_event(688, 78, "restart", "model_stap_bernoulli");
    reader.add_event(691, 81, "include", "/tparameters/tparameters_bernoulli.stan");
    reader.add_event(691, 0, "start", "/tparameters/tparameters_bernoulli.stan");
    reader.add_event(773, 82, "end", "/tparameters/tparameters_bernoulli.stan");
    reader.add_event(773, 82, "restart", "model_stap_bernoulli");
    reader.add_event(793, 102, "include", "/model/make_eta_bern.stan");
    reader.add_event(793, 0, "start", "/model/make_eta_bern.stan");
    reader.add_event(820, 27, "end", "/model/make_eta_bern.stan");
    reader.add_event(820, 103, "restart", "model_stap_bernoulli");
    reader.add_event(839, 122, "include", "/model/priors_glm.stan");
    reader.add_event(839, 0, "start", "/model/priors_glm.stan");
    reader.add_event(927, 88, "end", "/model/priors_glm.stan");
    reader.add_event(927, 123, "restart", "model_stap_bernoulli");
    reader.add_event(941, 137, "include", "/model/make_eta_bern.stan");
    reader.add_event(941, 0, "start", "/model/make_eta_bern.stan");
    reader.add_event(968, 27, "end", "/model/make_eta_bern.stan");
    reader.add_event(968, 138, "restart", "model_stap_bernoulli");
    reader.add_event(993, 161, "end", "model_stap_bernoulli");
    return reader;
}

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
centerscale(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& M, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 11;
        validate_non_negative_index("out", "cols(M)", cols(M));
        validate_non_negative_index("out", "rows(M)", rows(M));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> out(cols(M), rows(M));
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);


        current_statement_begin__ = 12;
        for (int q = 1; q <= cols(M); ++q) {
            current_statement_begin__ = 13;
            stan::model::assign(out, 
                        stan::model::cons_list(stan::model::index_uni(q), stan::model::nil_index_list()), 
                        transpose(divide(subtract(stan::model::rvalue(M, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(q), stan::model::nil_index_list())), "M"), mean(stan::model::rvalue(M, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(q), stan::model::nil_index_list())), "M"))), sd(stan::model::rvalue(M, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(q), stan::model::nil_index_list())), "M")))), 
                        "assigning variable out");
        }
        current_statement_begin__ = 14;
        return stan::math::promote_scalar<fun_return_scalar_t__>(transpose(out));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct centerscale_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, Eigen::Dynamic>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& M, std::ostream* pstream__) const {
        return centerscale(M, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
colmeans(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& M, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 21;
        validate_non_negative_index("ones", "rows(M)", rows(M));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> ones(rows(M));
        stan::math::initialize(ones, DUMMY_VAR__);
        stan::math::fill(ones, DUMMY_VAR__);
        stan::math::assign(ones,rep_vector(1.0, rows(M)));


        current_statement_begin__ = 22;
        return stan::math::promote_scalar<fun_return_scalar_t__>(divide(multiply(transpose(M), ones), rows(M)));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct colmeans_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& M, std::ostream* pstream__) const {
        return colmeans(M, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
colsds(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& M, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 30;
        validate_non_negative_index("out", "cols(M)", cols(M));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> out(cols(M));
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);


        current_statement_begin__ = 31;
        for (int col_ix = 1; col_ix <= cols(M); ++col_ix) {
            current_statement_begin__ = 32;
            stan::model::assign(out, 
                        stan::model::cons_list(stan::model::index_uni(col_ix), stan::model::nil_index_list()), 
                        sd(stan::model::rvalue(M, stan::model::cons_list(stan::model::index_omni(), stan::model::cons_list(stan::model::index_uni(col_ix), stan::model::nil_index_list())), "M")), 
                        "assigning variable out");
        }
        current_statement_begin__ = 33;
        return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct colsds_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, Eigen::Dynamic>& M, std::ostream* pstream__) const {
        return colsds(M, pstream__);
    }
};

template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic, 1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 56;
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> theta_L(len_theta_L);
        stan::math::initialize(theta_L, DUMMY_VAR__);
        stan::math::fill(theta_L, DUMMY_VAR__);

        current_statement_begin__ = 57;
        int zeta_mark(0);
        (void) zeta_mark;  // dummy to suppress unused var warning
        stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
        stan::math::assign(zeta_mark,1);

        current_statement_begin__ = 58;
        int rho_mark(0);
        (void) rho_mark;  // dummy to suppress unused var warning
        stan::math::fill(rho_mark, std::numeric_limits<int>::min());
        stan::math::assign(rho_mark,1);

        current_statement_begin__ = 59;
        int z_T_mark(0);
        (void) z_T_mark;  // dummy to suppress unused var warning
        stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
        stan::math::assign(z_T_mark,1);

        current_statement_begin__ = 60;
        int theta_L_mark(0);
        (void) theta_L_mark;  // dummy to suppress unused var warning
        stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
        stan::math::assign(theta_L_mark,1);


        current_statement_begin__ = 63;
        for (int i = 1; i <= size(p); ++i) {
            {
            current_statement_begin__ = 64;
            int nc(0);
            (void) nc;  // dummy to suppress unused var warning
            stan::math::fill(nc, std::numeric_limits<int>::min());
            stan::math::assign(nc,get_base1(p, i, "p", 1));


            current_statement_begin__ = 65;
            if (as_bool(logical_eq(nc, 1))) {

                current_statement_begin__ = 66;
                stan::model::assign(theta_L, 
                            stan::model::cons_list(stan::model::index_uni(theta_L_mark), stan::model::nil_index_list()), 
                            ((get_base1(tau, i, "tau", 1) * get_base1(scale, i, "scale", 1)) * dispersion), 
                            "assigning variable theta_L");
                current_statement_begin__ = 68;
                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
            } else {
                {
                current_statement_begin__ = 71;
                validate_non_negative_index("T_i", "nc", nc);
                validate_non_negative_index("T_i", "nc", nc);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> T_i(nc, nc);
                stan::math::initialize(T_i, DUMMY_VAR__);
                stan::math::fill(T_i, DUMMY_VAR__);

                current_statement_begin__ = 72;
                local_scalar_t__ std_dev(DUMMY_VAR__);
                (void) std_dev;  // dummy to suppress unused var warning
                stan::math::initialize(std_dev, DUMMY_VAR__);
                stan::math::fill(std_dev, DUMMY_VAR__);

                current_statement_begin__ = 73;
                local_scalar_t__ T21(DUMMY_VAR__);
                (void) T21;  // dummy to suppress unused var warning
                stan::math::initialize(T21, DUMMY_VAR__);
                stan::math::fill(T21, DUMMY_VAR__);

                current_statement_begin__ = 74;
                local_scalar_t__ trace_T_i(DUMMY_VAR__);
                (void) trace_T_i;  // dummy to suppress unused var warning
                stan::math::initialize(trace_T_i, DUMMY_VAR__);
                stan::math::fill(trace_T_i, DUMMY_VAR__);
                stan::math::assign(trace_T_i,(square(((get_base1(tau, i, "tau", 1) * get_base1(scale, i, "scale", 1)) * dispersion)) * nc));

                current_statement_begin__ = 75;
                validate_non_negative_index("pi", "nc", nc);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> pi(nc);
                stan::math::initialize(pi, DUMMY_VAR__);
                stan::math::fill(pi, DUMMY_VAR__);
                stan::math::assign(pi,segment(zeta, zeta_mark, nc));


                current_statement_begin__ = 76;
                stan::math::assign(pi, divide(pi, sum(pi)));
                current_statement_begin__ = 79;
                stan::math::assign(zeta_mark, (zeta_mark + nc));
                current_statement_begin__ = 80;
                stan::math::assign(std_dev, stan::math::sqrt((get_base1(pi, 1, "pi", 1) * trace_T_i)));
                current_statement_begin__ = 81;
                stan::model::assign(T_i, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), 
                            std_dev, 
                            "assigning variable T_i");
                current_statement_begin__ = 84;
                stan::math::assign(std_dev, stan::math::sqrt((get_base1(pi, 2, "pi", 1) * trace_T_i)));
                current_statement_begin__ = 85;
                stan::math::assign(T21, ((2.0 * get_base1(rho, rho_mark, "rho", 1)) - 1.0));
                current_statement_begin__ = 86;
                stan::math::assign(rho_mark, (rho_mark + 1));
                current_statement_begin__ = 87;
                stan::model::assign(T_i, 
                            stan::model::cons_list(stan::model::index_uni(2), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), 
                            (std_dev * stan::math::sqrt((1.0 - square(T21)))), 
                            "assigning variable T_i");
                current_statement_begin__ = 88;
                stan::model::assign(T_i, 
                            stan::model::cons_list(stan::model::index_uni(2), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), 
                            (std_dev * T21), 
                            "assigning variable T_i");
                current_statement_begin__ = 90;
                for (int r = 2; r <= (nc - 1); ++r) {
                    {
                    current_statement_begin__ = 91;
                    int rp1(0);
                    (void) rp1;  // dummy to suppress unused var warning
                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                    stan::math::assign(rp1,(r + 1));

                    current_statement_begin__ = 92;
                    validate_non_negative_index("T_row", "r", r);
                    Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> T_row(r);
                    stan::math::initialize(T_row, DUMMY_VAR__);
                    stan::math::fill(T_row, DUMMY_VAR__);
                    stan::math::assign(T_row,segment(z_T, z_T_mark, r));

                    current_statement_begin__ = 93;
                    local_scalar_t__ scale_factor(DUMMY_VAR__);
                    (void) scale_factor;  // dummy to suppress unused var warning
                    stan::math::initialize(scale_factor, DUMMY_VAR__);
                    stan::math::fill(scale_factor, DUMMY_VAR__);
                    stan::math::assign(scale_factor,(stan::math::sqrt((get_base1(rho, rho_mark, "rho", 1) / dot_self(T_row))) * std_dev));


                    current_statement_begin__ = 94;
                    stan::math::assign(z_T_mark, (z_T_mark + r));
                    current_statement_begin__ = 95;
                    stan::math::assign(std_dev, stan::math::sqrt((get_base1(pi, rp1, "pi", 1) * trace_T_i)));
                    current_statement_begin__ = 96;
                    for (int c = 1; c <= r; ++c) {
                        current_statement_begin__ = 96;
                        stan::model::assign(T_i, 
                                    stan::model::cons_list(stan::model::index_uni(rp1), stan::model::cons_list(stan::model::index_uni(c), stan::model::nil_index_list())), 
                                    (get_base1(T_row, c, "T_row", 1) * scale_factor), 
                                    "assigning variable T_i");
                    }
                    current_statement_begin__ = 97;
                    stan::model::assign(T_i, 
                                stan::model::cons_list(stan::model::index_uni(rp1), stan::model::cons_list(stan::model::index_uni(rp1), stan::model::nil_index_list())), 
                                (stan::math::sqrt((1.0 - get_base1(rho, rho_mark, "rho", 1))) * std_dev), 
                                "assigning variable T_i");
                    current_statement_begin__ = 98;
                    stan::math::assign(rho_mark, (rho_mark + 1));
                    }
                }
                current_statement_begin__ = 102;
                for (int c = 1; c <= nc; ++c) {
                    current_statement_begin__ = 102;
                    for (int r = c; r <= nc; ++r) {

                        current_statement_begin__ = 103;
                        stan::model::assign(theta_L, 
                                    stan::model::cons_list(stan::model::index_uni(theta_L_mark), stan::model::nil_index_list()), 
                                    get_base1(T_i, r, c, "T_i", 1), 
                                    "assigning variable theta_L");
                        current_statement_begin__ = 104;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    }
                }
                }
            }
            }
        }
        current_statement_begin__ = 108;
        return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic, 1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 123;
        validate_non_negative_index("b", "rows(z_b)", rows(z_b));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> b(rows(z_b));
        stan::math::initialize(b, DUMMY_VAR__);
        stan::math::fill(b, DUMMY_VAR__);

        current_statement_begin__ = 124;
        int b_mark(0);
        (void) b_mark;  // dummy to suppress unused var warning
        stan::math::fill(b_mark, std::numeric_limits<int>::min());
        stan::math::assign(b_mark,1);

        current_statement_begin__ = 125;
        int theta_L_mark(0);
        (void) theta_L_mark;  // dummy to suppress unused var warning
        stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
        stan::math::assign(theta_L_mark,1);


        current_statement_begin__ = 126;
        for (int i = 1; i <= size(p); ++i) {
            {
            current_statement_begin__ = 127;
            int nc(0);
            (void) nc;  // dummy to suppress unused var warning
            stan::math::fill(nc, std::numeric_limits<int>::min());
            stan::math::assign(nc,get_base1(p, i, "p", 1));


            current_statement_begin__ = 128;
            if (as_bool(logical_eq(nc, 1))) {
                {
                current_statement_begin__ = 129;
                local_scalar_t__ theta_L_start(DUMMY_VAR__);
                (void) theta_L_start;  // dummy to suppress unused var warning
                stan::math::initialize(theta_L_start, DUMMY_VAR__);
                stan::math::fill(theta_L_start, DUMMY_VAR__);
                stan::math::assign(theta_L_start,get_base1(theta_L, theta_L_mark, "theta_L", 1));


                current_statement_begin__ = 130;
                for (int s = b_mark; s <= ((b_mark + get_base1(l, i, "l", 1)) - 1); ++s) {
                    current_statement_begin__ = 131;
                    stan::model::assign(b, 
                                stan::model::cons_list(stan::model::index_uni(s), stan::model::nil_index_list()), 
                                (theta_L_start * get_base1(z_b, s, "z_b", 1)), 
                                "assigning variable b");
                }
                current_statement_begin__ = 132;
                stan::math::assign(b_mark, (b_mark + get_base1(l, i, "l", 1)));
                current_statement_begin__ = 133;
                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                }
            } else {
                {
                current_statement_begin__ = 136;
                validate_non_negative_index("T_i", "nc", nc);
                validate_non_negative_index("T_i", "nc", nc);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> T_i(nc, nc);
                stan::math::initialize(T_i, DUMMY_VAR__);
                stan::math::fill(T_i, DUMMY_VAR__);
                stan::math::assign(T_i,rep_matrix(0, nc, nc));


                current_statement_begin__ = 137;
                for (int c = 1; c <= nc; ++c) {

                    current_statement_begin__ = 138;
                    stan::model::assign(T_i, 
                                stan::model::cons_list(stan::model::index_uni(c), stan::model::cons_list(stan::model::index_uni(c), stan::model::nil_index_list())), 
                                get_base1(theta_L, theta_L_mark, "theta_L", 1), 
                                "assigning variable T_i");
                    current_statement_begin__ = 139;
                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    current_statement_begin__ = 140;
                    for (int r = (c + 1); r <= nc; ++r) {

                        current_statement_begin__ = 141;
                        stan::model::assign(T_i, 
                                    stan::model::cons_list(stan::model::index_uni(r), stan::model::cons_list(stan::model::index_uni(c), stan::model::nil_index_list())), 
                                    get_base1(theta_L, theta_L_mark, "theta_L", 1), 
                                    "assigning variable T_i");
                        current_statement_begin__ = 142;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    }
                }
                current_statement_begin__ = 145;
                for (int j = 1; j <= get_base1(l, i, "l", 1); ++j) {
                    {
                    current_statement_begin__ = 146;
                    validate_non_negative_index("temp", "nc", nc);
                    Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> temp(nc);
                    stan::math::initialize(temp, DUMMY_VAR__);
                    stan::math::fill(temp, DUMMY_VAR__);
                    stan::math::assign(temp,multiply(T_i, segment(z_b, b_mark, nc)));


                    current_statement_begin__ = 147;
                    stan::math::assign(b_mark, (b_mark - 1));
                    current_statement_begin__ = 148;
                    for (int s = 1; s <= nc; ++s) {
                        current_statement_begin__ = 148;
                        stan::model::assign(b, 
                                    stan::model::cons_list(stan::model::index_uni((b_mark + s)), stan::model::nil_index_list()), 
                                    get_base1(temp, s, "temp", 1), 
                                    "assigning variable b");
                    }
                    current_statement_begin__ = 149;
                    stan::math::assign(b_mark, ((b_mark + nc) + 1));
                    }
                }
                }
            }
            }
        }
        current_statement_begin__ = 153;
        return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
void
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 174;
        int pos_reg(0);
        (void) pos_reg;  // dummy to suppress unused var warning
        stan::math::fill(pos_reg, std::numeric_limits<int>::min());
        stan::math::assign(pos_reg,1);

        current_statement_begin__ = 175;
        int pos_rho(0);
        (void) pos_rho;  // dummy to suppress unused var warning
        stan::math::fill(pos_rho, std::numeric_limits<int>::min());
        stan::math::assign(pos_rho,1);


        current_statement_begin__ = 176;
        lp_accum__.add(normal_log(z_b, 0, 1));
        current_statement_begin__ = 177;
        lp_accum__.add(normal_log(z_T, 0, 1));
        current_statement_begin__ = 178;
        for (int i = 1; i <= t; ++i) {
            current_statement_begin__ = 178;
            if (as_bool(logical_gt(get_base1(p, i, "p", 1), 1))) {
                {
                current_statement_begin__ = 179;
                validate_non_negative_index("shape1", "(get_base1(p, i, \"p\", 1) - 1)", (get_base1(p, i, "p", 1) - 1));
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> shape1((get_base1(p, i, "p", 1) - 1));
                stan::math::initialize(shape1, DUMMY_VAR__);
                stan::math::fill(shape1, DUMMY_VAR__);

                current_statement_begin__ = 180;
                validate_non_negative_index("shape2", "(get_base1(p, i, \"p\", 1) - 1)", (get_base1(p, i, "p", 1) - 1));
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> shape2((get_base1(p, i, "p", 1) - 1));
                stan::math::initialize(shape2, DUMMY_VAR__);
                stan::math::fill(shape2, DUMMY_VAR__);

                current_statement_begin__ = 181;
                local_scalar_t__ nu(DUMMY_VAR__);
                (void) nu;  // dummy to suppress unused var warning
                stan::math::initialize(nu, DUMMY_VAR__);
                stan::math::fill(nu, DUMMY_VAR__);
                stan::math::assign(nu,(get_base1(regularization, pos_reg, "regularization", 1) + (0.5 * (get_base1(p, i, "p", 1) - 2))));


                current_statement_begin__ = 182;
                stan::math::assign(pos_reg, (pos_reg + 1));
                current_statement_begin__ = 183;
                stan::model::assign(shape1, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            nu, 
                            "assigning variable shape1");
                current_statement_begin__ = 184;
                stan::model::assign(shape2, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            nu, 
                            "assigning variable shape2");
                current_statement_begin__ = 185;
                for (int j = 2; j <= (get_base1(p, i, "p", 1) - 1); ++j) {

                    current_statement_begin__ = 186;
                    stan::math::assign(nu, (nu - 0.5));
                    current_statement_begin__ = 187;
                    stan::model::assign(shape1, 
                                stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                                (0.5 * j), 
                                "assigning variable shape1");
                    current_statement_begin__ = 188;
                    stan::model::assign(shape2, 
                                stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                                nu, 
                                "assigning variable shape2");
                }
                current_statement_begin__ = 190;
                lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p, i, "p", 1)) - 2)), stan::model::nil_index_list()), "rho"), shape1, shape2));
                current_statement_begin__ = 191;
                stan::math::assign(pos_rho, ((pos_rho + get_base1(p, i, "p", 1)) - 1));
                }
            }
        }
        current_statement_begin__ = 193;
        lp_accum__.add(gamma_log(zeta, delta, 1));
        current_statement_begin__ = 194;
        lp_accum__.add(gamma_log(tau, shape, 1));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        void
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale,
             const T5__& c2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 211;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(z_beta));

        current_statement_begin__ = 212;
        validate_non_negative_index("lambda", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda(K);
        stan::math::initialize(lambda, DUMMY_VAR__);
        stan::math::fill(lambda, DUMMY_VAR__);
        stan::math::assign(lambda,elt_multiply(get_base1(local, 1, "local", 1), stan::math::sqrt(get_base1(local, 2, "local", 1))));

        current_statement_begin__ = 213;
        local_scalar_t__ tau(DUMMY_VAR__);
        (void) tau;  // dummy to suppress unused var warning
        stan::math::initialize(tau, DUMMY_VAR__);
        stan::math::fill(tau, DUMMY_VAR__);
        stan::math::assign(tau,(((get_base1(global, 1, "global", 1) * stan::math::sqrt(get_base1(global, 2, "global", 1))) * global_prior_scale) * error_scale));

        current_statement_begin__ = 214;
        validate_non_negative_index("lambda2", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda2(K);
        stan::math::initialize(lambda2, DUMMY_VAR__);
        stan::math::fill(lambda2, DUMMY_VAR__);
        stan::math::assign(lambda2,square(lambda));

        current_statement_begin__ = 215;
        validate_non_negative_index("lambda_tilde", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda_tilde(K);
        stan::math::initialize(lambda_tilde, DUMMY_VAR__);
        stan::math::fill(lambda_tilde, DUMMY_VAR__);
        stan::math::assign(lambda_tilde,stan::math::sqrt(elt_divide(multiply(c2, lambda2), add(c2, multiply(square(tau), lambda2)))));


        current_statement_begin__ = 216;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(elt_multiply(z_beta, lambda_tilde), tau));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale,
             const T5__& c2, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, c2, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale,
                 const T5__& c2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 232;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(z_beta));

        current_statement_begin__ = 233;
        validate_non_negative_index("lambda", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda(K);
        stan::math::initialize(lambda, DUMMY_VAR__);
        stan::math::fill(lambda, DUMMY_VAR__);
        stan::math::assign(lambda,elt_multiply(get_base1(local, 1, "local", 1), stan::math::sqrt(get_base1(local, 2, "local", 1))));

        current_statement_begin__ = 234;
        validate_non_negative_index("eta", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta(K);
        stan::math::initialize(eta, DUMMY_VAR__);
        stan::math::fill(eta, DUMMY_VAR__);
        stan::math::assign(eta,elt_multiply(get_base1(local, 3, "local", 1), stan::math::sqrt(get_base1(local, 4, "local", 1))));

        current_statement_begin__ = 235;
        local_scalar_t__ tau(DUMMY_VAR__);
        (void) tau;  // dummy to suppress unused var warning
        stan::math::initialize(tau, DUMMY_VAR__);
        stan::math::fill(tau, DUMMY_VAR__);
        stan::math::assign(tau,(((get_base1(global, 1, "global", 1) * stan::math::sqrt(get_base1(global, 2, "global", 1))) * global_prior_scale) * error_scale));

        current_statement_begin__ = 236;
        validate_non_negative_index("lambda_eta2", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda_eta2(K);
        stan::math::initialize(lambda_eta2, DUMMY_VAR__);
        stan::math::fill(lambda_eta2, DUMMY_VAR__);
        stan::math::assign(lambda_eta2,square(elt_multiply(lambda, eta)));

        current_statement_begin__ = 237;
        validate_non_negative_index("lambda_tilde", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda_tilde(K);
        stan::math::initialize(lambda_tilde, DUMMY_VAR__);
        stan::math::fill(lambda_tilde, DUMMY_VAR__);
        stan::math::assign(lambda_tilde,stan::math::sqrt(elt_divide(multiply(c2, lambda_eta2), add(c2, multiply(square(tau), lambda_eta2)))));


        current_statement_begin__ = 239;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(elt_multiply(z_beta, lambda_tilde), tau));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale,
                 const T5__& c2, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, c2, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 253;
        local_scalar_t__ z2(DUMMY_VAR__);
        (void) z2;  // dummy to suppress unused var warning
        stan::math::initialize(z2, DUMMY_VAR__);
        stan::math::fill(z2, DUMMY_VAR__);
        stan::math::assign(z2,square(z));

        current_statement_begin__ = 254;
        local_scalar_t__ z3(DUMMY_VAR__);
        (void) z3;  // dummy to suppress unused var warning
        stan::math::initialize(z3, DUMMY_VAR__);
        stan::math::fill(z3, DUMMY_VAR__);
        stan::math::assign(z3,(z2 * z));

        current_statement_begin__ = 255;
        local_scalar_t__ z5(DUMMY_VAR__);
        (void) z5;  // dummy to suppress unused var warning
        stan::math::initialize(z5, DUMMY_VAR__);
        stan::math::fill(z5, DUMMY_VAR__);
        stan::math::assign(z5,(z2 * z3));

        current_statement_begin__ = 256;
        local_scalar_t__ z7(DUMMY_VAR__);
        (void) z7;  // dummy to suppress unused var warning
        stan::math::initialize(z7, DUMMY_VAR__);
        stan::math::fill(z7, DUMMY_VAR__);
        stan::math::assign(z7,(z2 * z5));

        current_statement_begin__ = 257;
        local_scalar_t__ z9(DUMMY_VAR__);
        (void) z9;  // dummy to suppress unused var warning
        stan::math::initialize(z9, DUMMY_VAR__);
        stan::math::fill(z9, DUMMY_VAR__);
        stan::math::assign(z9,(z2 * z7));

        current_statement_begin__ = 258;
        local_scalar_t__ df2(DUMMY_VAR__);
        (void) df2;  // dummy to suppress unused var warning
        stan::math::initialize(df2, DUMMY_VAR__);
        stan::math::fill(df2, DUMMY_VAR__);
        stan::math::assign(df2,square(df));

        current_statement_begin__ = 259;
        local_scalar_t__ df3(DUMMY_VAR__);
        (void) df3;  // dummy to suppress unused var warning
        stan::math::initialize(df3, DUMMY_VAR__);
        stan::math::fill(df3, DUMMY_VAR__);
        stan::math::assign(df3,(df2 * df));

        current_statement_begin__ = 260;
        local_scalar_t__ df4(DUMMY_VAR__);
        (void) df4;  // dummy to suppress unused var warning
        stan::math::initialize(df4, DUMMY_VAR__);
        stan::math::fill(df4, DUMMY_VAR__);
        stan::math::assign(df4,(df2 * df2));


        current_statement_begin__ = 261;
        return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

std::vector<std::vector<int> >
make_V(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) {
    typedef double local_scalar_t__;
    typedef int fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 275;
        validate_non_negative_index("V", "t", t);
        validate_non_negative_index("V", "N", N);
        std::vector<std::vector<int  >  > V(t, std::vector<int>(N, int(0)));
        stan::math::fill(V, std::numeric_limits<int>::min());

        current_statement_begin__ = 276;
        int pos(0);
        (void) pos;  // dummy to suppress unused var warning
        stan::math::fill(pos, std::numeric_limits<int>::min());
        stan::math::assign(pos,1);


        current_statement_begin__ = 277;
        if (as_bool(logical_gt(t, 0))) {
            current_statement_begin__ = 277;
            for (int j = 1; j <= N; ++j) {
                current_statement_begin__ = 277;
                for (int i = 1; i <= t; ++i) {

                    current_statement_begin__ = 278;
                    stan::model::assign(V, 
                                stan::model::cons_list(stan::model::index_uni(i), stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list())), 
                                get_base1(v, pos, "v", 1), 
                                "assigning variable V");
                    current_statement_begin__ = 279;
                    stan::math::assign(pos, (pos + 1));
                }
            }
        }
        current_statement_begin__ = 281;
        return stan::math::promote_scalar<fun_return_scalar_t__>(V);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_V_functor__ {
            std::vector<std::vector<int> >
    operator()(const int& N,
           const int& t,
           const std::vector<int>& v, std::ostream* pstream__) const {
        return make_V(N, t, v, pstream__);
    }
};

double
make_lower(const int& family,
               const int& link, std::ostream* pstream__) {
    typedef double local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 300;
        if (as_bool(logical_eq(family, 1))) {
            current_statement_begin__ = 300;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
        }
        current_statement_begin__ = 301;
        if (as_bool(logical_lte(family, 3))) {

            current_statement_begin__ = 302;
            if (as_bool(logical_eq(link, 2))) {
                current_statement_begin__ = 302;
                return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
            }
            current_statement_begin__ = 303;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        }
        current_statement_begin__ = 305;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::negative_infinity());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_lower_functor__ {
            double
    operator()(const int& family,
               const int& link, std::ostream* pstream__) const {
        return make_lower(family, link, pstream__);
    }
};

double
make_upper(const int& family,
               const int& link, std::ostream* pstream__) {
    typedef double local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 316;
        if (as_bool((primitive_value(logical_eq(family, 4)) && primitive_value(logical_eq(link, 5))))) {
            current_statement_begin__ = 316;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        }
        current_statement_begin__ = 317;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::positive_infinity());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_upper_functor__ {
            double
    operator()(const int& family,
               const int& link, std::ostream* pstream__) const {
        return make_upper(family, link, pstream__);
    }
};

template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
expo_vec(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& in,
             const T1__& to_pow, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 328;
        validate_non_negative_index("out", "rows(in)", rows(in));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> out(rows(in));
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);


        current_statement_begin__ = 329;
        for (int i = 1; i <= rows(in); ++i) {
            current_statement_begin__ = 330;
            stan::model::assign(out, 
                        stan::model::cons_list(stan::model::index_uni(i), stan::model::nil_index_list()), 
                        pow(get_base1(in, i, "in", 1), to_pow), 
                        "assigning variable out");
        }
        current_statement_begin__ = 331;
        return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct expo_vec_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& in,
             const T1__& to_pow, std::ostream* pstream__) const {
        return expo_vec(in, to_pow, pstream__);
    }
};

template <typename T0__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T2__>::type, Eigen::Dynamic, 1>
get_weights(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& exposure,
                const int& w,
                const std::vector<T2__>& shape,
                const int& cnt_shape, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 342;
        if (as_bool(logical_eq(w, 1))) {
            current_statement_begin__ = 343;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::erf(exposure));
        } else if (as_bool(logical_eq(w, 2))) {
            current_statement_begin__ = 345;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::erfc(exposure));
        } else if (as_bool(logical_eq(w, 3))) {
            current_statement_begin__ = 347;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::exp(minus(exposure)));
        } else if (as_bool(logical_eq(w, 4))) {
            current_statement_begin__ = 349;
            return stan::math::promote_scalar<fun_return_scalar_t__>(subtract(1, stan::math::exp(minus(exposure))));
        } else if (as_bool(logical_eq(w, 5))) {
            current_statement_begin__ = 351;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::exp(minus(expo_vec(exposure, get_base1(shape, cnt_shape, "shape", 1), pstream__))));
        } else {
            current_statement_begin__ = 353;
            return stan::math::promote_scalar<fun_return_scalar_t__>(subtract(1, stan::math::exp(minus(expo_vec(exposure, get_base1(shape, cnt_shape, "shape", 1), pstream__)))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct get_weights_functor__ {
    template <typename T0__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T2__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& exposure,
                const int& w,
                const std::vector<T2__>& shape,
                const int& cnt_shape, std::ostream* pstream__) const {
        return get_weights(exposure, w, shape, cnt_shape, pstream__);
    }
};

template <typename T3__, typename T4__, typename T5__>
typename boost::math::tools::promote_args<T3__, T4__, T5__>::type
assign_exposure(const int& log_switch,
                    const int& w,
                    const std::vector<std::vector<int> >& u,
                    const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& time_dists,
                    const T4__& theta,
                    const std::vector<T5__>& shape,
                    const int& cnt_shape,
                    const int& q,
                    const int& n, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T3__, T4__, T5__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 367;
        local_scalar_t__ out(DUMMY_VAR__);
        (void) out;  // dummy to suppress unused var warning
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);


        current_statement_begin__ = 368;
        if (as_bool(logical_gt(get_base1(get_base1(u, n, "u", 1), ((q * 2) - 1), "u", 2), get_base1(get_base1(u, n, "u", 1), (q * 2), "u", 2)))) {
            current_statement_begin__ = 369;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        } else {
            current_statement_begin__ = 371;
            stan::math::assign(out, sum(get_weights(multiply(stan::model::rvalue(time_dists, stan::model::cons_list(stan::model::index_min_max(get_base1(get_base1(u, n, "u", 1), ((q * 2) - 1), "u", 2), get_base1(get_base1(u, n, "u", 1), (q * 2), "u", 2)), stan::model::nil_index_list()), "time_dists"), inv(theta)), w, shape, cnt_shape, pstream__)));
        }
        current_statement_begin__ = 372;
        if (as_bool(logical_eq(log_switch, 1))) {
            current_statement_begin__ = 373;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::log(out));
        } else {
            current_statement_begin__ = 375;
            return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct assign_exposure_functor__ {
    template <typename T3__, typename T4__, typename T5__>
        typename boost::math::tools::promote_args<T3__, T4__, T5__>::type
    operator()(const int& log_switch,
                    const int& w,
                    const std::vector<std::vector<int> >& u,
                    const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& time_dists,
                    const T4__& theta,
                    const std::vector<T5__>& shape,
                    const int& cnt_shape,
                    const int& q,
                    const int& n, std::ostream* pstream__) const {
        return assign_exposure(log_switch, w, u, time_dists, theta, shape, cnt_shape, q, n, pstream__);
    }
};

template <typename T5__, typename T6__, typename T7__, typename T8__, typename T9__, typename T10__>
typename boost::math::tools::promote_args<T5__, T6__, T7__, T8__, typename boost::math::tools::promote_args<T9__, T10__>::type>::type
assign_st_exposure(const int& log_switch,
                       const int& w_s,
                       const int& w_t,
                       const std::vector<std::vector<int> >& u_s,
                       const std::vector<std::vector<int> >& u_t,
                       const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& dists,
                       const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& time,
                       const T7__& theta_s,
                       const T8__& theta_t,
                       const std::vector<T9__>& shape_s,
                       const std::vector<T10__>& shape_t,
                       const int& cnt_shape_s,
                       const int& cnt_shape_t,
                       const int& q,
                       const int& n, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T5__, T6__, T7__, T8__, typename boost::math::tools::promote_args<T9__, T10__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 388;
        local_scalar_t__ out(DUMMY_VAR__);
        (void) out;  // dummy to suppress unused var warning
        stan::math::initialize(out, DUMMY_VAR__);
        stan::math::fill(out, DUMMY_VAR__);


        current_statement_begin__ = 389;
        if (as_bool(logical_gt(get_base1(get_base1(u_s, n, "u_s", 1), ((q * 2) - 1), "u_s", 2), get_base1(get_base1(u_s, n, "u_s", 1), (q * 2), "u_s", 2)))) {
            current_statement_begin__ = 390;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        } else {
            current_statement_begin__ = 392;
            stan::math::assign(out, sum(elt_multiply(get_weights(multiply(stan::model::rvalue(dists, stan::model::cons_list(stan::model::index_min_max(get_base1(get_base1(u_s, n, "u_s", 1), ((q * 2) - 1), "u_s", 2), get_base1(get_base1(u_s, n, "u_s", 1), (q * 2), "u_s", 2)), stan::model::nil_index_list()), "dists"), inv(theta_s)), w_s, shape_s, cnt_shape_s, pstream__), get_weights(multiply(stan::model::rvalue(time, stan::model::cons_list(stan::model::index_min_max(get_base1(get_base1(u_t, n, "u_t", 1), ((q * 2) - 1), "u_t", 2), get_base1(get_base1(u_t, n, "u_t", 1), (q * 2), "u_t", 2)), stan::model::nil_index_list()), "time"), inv(theta_t)), w_t, shape_t, cnt_shape_t, pstream__))));
        }
        current_statement_begin__ = 394;
        if (as_bool(logical_eq(log_switch, 1))) {
            current_statement_begin__ = 395;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::log(out));
        } else {
            current_statement_begin__ = 397;
            return stan::math::promote_scalar<fun_return_scalar_t__>(out);
        }
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct assign_st_exposure_functor__ {
    template <typename T5__, typename T6__, typename T7__, typename T8__, typename T9__, typename T10__>
        typename boost::math::tools::promote_args<T5__, T6__, T7__, T8__, typename boost::math::tools::promote_args<T9__, T10__>::type>::type
    operator()(const int& log_switch,
                       const int& w_s,
                       const int& w_t,
                       const std::vector<std::vector<int> >& u_s,
                       const std::vector<std::vector<int> >& u_t,
                       const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& dists,
                       const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& time,
                       const T7__& theta_s,
                       const T8__& theta_t,
                       const std::vector<T9__>& shape_s,
                       const std::vector<T10__>& shape_t,
                       const int& cnt_shape_s,
                       const int& cnt_shape_t,
                       const int& q,
                       const int& n, std::ostream* pstream__) const {
        return assign_st_exposure(log_switch, w_s, w_t, u_s, u_t, dists, time, theta_s, theta_t, shape_s, shape_t, cnt_shape_s, cnt_shape_t, q, n, pstream__);
    }
};

template <typename T0__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
linkinv_bern(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& eta,
                 const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 408;
        if (as_bool(logical_eq(link, 1))) {
            current_statement_begin__ = 408;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_logit(eta));
        } else if (as_bool(logical_eq(link, 2))) {
            current_statement_begin__ = 409;
            return stan::math::promote_scalar<fun_return_scalar_t__>(Phi(eta));
        } else if (as_bool(logical_eq(link, 3))) {
            current_statement_begin__ = 410;
            return stan::math::promote_scalar<fun_return_scalar_t__>(add(divide(stan::math::atan(eta), stan::math::pi()), 0.5));
        } else if (as_bool(logical_eq(link, 4))) {
            current_statement_begin__ = 411;
            return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::exp(eta));
        } else if (as_bool(logical_eq(link, 5))) {
            current_statement_begin__ = 412;
            return stan::math::promote_scalar<fun_return_scalar_t__>(inv_cloglog(eta));
        } else {
            current_statement_begin__ = 413;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 414;
        return stan::math::promote_scalar<fun_return_scalar_t__>(eta);
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct linkinv_bern_functor__ {
    template <typename T0__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& eta,
                 const int& link, std::ostream* pstream__) const {
        return linkinv_bern(eta, link, pstream__);
    }
};

template <typename T0__, typename T1__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type
ll_bern_lp(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& eta0,
               const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta1,
               const int& link,
               const std::vector<int>& N, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 427;
        if (as_bool(logical_eq(link, 1))) {

            current_statement_begin__ = 428;
            lp_accum__.add(logistic_ccdf_log(eta0, 0, 1));
            current_statement_begin__ = 429;
            lp_accum__.add(logistic_cdf_log(eta1, 0, 1));
        } else if (as_bool(logical_eq(link, 2))) {

            current_statement_begin__ = 432;
            lp_accum__.add(normal_ccdf_log(eta0, 0, 1));
            current_statement_begin__ = 433;
            lp_accum__.add(normal_cdf_log(eta1, 0, 1));
        } else if (as_bool(logical_eq(link, 3))) {

            current_statement_begin__ = 436;
            lp_accum__.add(cauchy_ccdf_log(eta0, 0, 1));
            current_statement_begin__ = 437;
            lp_accum__.add(cauchy_cdf_log(eta1, 0, 1));
        } else if (as_bool(logical_eq(link, 4))) {

            current_statement_begin__ = 440;
            lp_accum__.add(log1m_exp(eta0));
            current_statement_begin__ = 441;
            lp_accum__.add(eta1);
        } else if (as_bool(logical_eq(link, 5))) {

            current_statement_begin__ = 444;
            lp_accum__.add(log1m_exp(minus(stan::math::exp(eta1))));
            current_statement_begin__ = 445;
            lp_accum__.add(minus(stan::math::exp(eta0)));
        } else {
            current_statement_begin__ = 447;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 448;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct ll_bern_lp_functor__ {
    template <typename T0__, typename T1__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& eta0,
               const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta1,
               const int& link,
               const std::vector<int>& N, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return ll_bern_lp(eta0, eta1, link, N, lp__, lp_accum__, pstream__);
    }
};

template <typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic, 1>
pw_bern(const int& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta,
            const int& link, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 461;
        int N(0);
        (void) N;  // dummy to suppress unused var warning
        stan::math::fill(N, std::numeric_limits<int>::min());
        stan::math::assign(N,rows(eta));

        current_statement_begin__ = 462;
        validate_non_negative_index("ll", "N", N);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> ll(N);
        stan::math::initialize(ll, DUMMY_VAR__);
        stan::math::fill(ll, DUMMY_VAR__);


        current_statement_begin__ = 463;
        if (as_bool(logical_eq(link, 1))) {

            current_statement_begin__ = 464;
            for (int n = 1; n <= N; ++n) {
                current_statement_begin__ = 464;
                stan::model::assign(ll, 
                            stan::model::cons_list(stan::model::index_uni(n), stan::model::nil_index_list()), 
                            bernoulli_logit_log(y, get_base1(eta, n, "eta", 1)), 
                            "assigning variable ll");
            }
        } else if (as_bool(logical_lte(link, 5))) {
            {
            current_statement_begin__ = 467;
            validate_non_negative_index("pi", "N", N);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> pi(N);
            stan::math::initialize(pi, DUMMY_VAR__);
            stan::math::fill(pi, DUMMY_VAR__);
            stan::math::assign(pi,linkinv_bern(eta, link, pstream__));


            current_statement_begin__ = 468;
            for (int n = 1; n <= N; ++n) {
                current_statement_begin__ = 468;
                stan::model::assign(ll, 
                            stan::model::cons_list(stan::model::index_uni(n), stan::model::nil_index_list()), 
                            bernoulli_log(y, get_base1(pi, n, "pi", 1)), 
                            "assigning variable ll");
            }
            }
        } else {
            current_statement_begin__ = 470;
            std::stringstream errmsg_stream__;
            errmsg_stream__ << "Invalid link";
            throw std::domain_error(errmsg_stream__.str());
        }
        current_statement_begin__ = 471;
        return stan::math::promote_scalar<fun_return_scalar_t__>(ll);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_bern_functor__ {
    template <typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T1__>::type, Eigen::Dynamic, 1>
    operator()(const int& y,
            const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta,
            const int& link, std::ostream* pstream__) const {
        return pw_bern(y, eta, link, pstream__);
    }
};

template <typename T2__>
typename boost::math::tools::promote_args<T2__>::type
log_clogit_denom(const int& N_j,
                     const int& D_j,
                     const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& eta_j, std::ostream* pstream__);

template <typename T2__>
typename boost::math::tools::promote_args<T2__>::type
log_clogit_denom(const int& N_j,
                     const int& D_j,
                     const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& eta_j, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 484;
        if (as_bool((primitive_value(logical_eq(D_j, 1)) && primitive_value(logical_eq(N_j, rows(eta_j)))))) {
            current_statement_begin__ = 484;
            return stan::math::promote_scalar<fun_return_scalar_t__>(log_sum_exp(eta_j));
        }
        current_statement_begin__ = 485;
        if (as_bool(logical_eq(D_j, 0))) {
            current_statement_begin__ = 485;
            return stan::math::promote_scalar<fun_return_scalar_t__>(0);
        }
        current_statement_begin__ = 486;
        if (as_bool(logical_eq(N_j, D_j))) {

            current_statement_begin__ = 487;
            if (as_bool(logical_eq(D_j, 1))) {
                current_statement_begin__ = 487;
                return stan::math::promote_scalar<fun_return_scalar_t__>(get_base1(eta_j, N_j, "eta_j", 1));
            }
            current_statement_begin__ = 488;
            return stan::math::promote_scalar<fun_return_scalar_t__>(sum(segment(eta_j, (N_j - 1), 2)));
        } else {
            {
            current_statement_begin__ = 491;
            int N_jm1(0);
            (void) N_jm1;  // dummy to suppress unused var warning
            stan::math::fill(N_jm1, std::numeric_limits<int>::min());
            stan::math::assign(N_jm1,(N_j - 1));


            current_statement_begin__ = 492;
            return stan::math::promote_scalar<fun_return_scalar_t__>(log_sum_exp(log_clogit_denom(N_jm1, D_j, eta_j, pstream__), (log_clogit_denom(N_jm1, (D_j - 1), eta_j, pstream__) + get_base1(eta_j, N_j, "eta_j", 1))));
            }
        }
        current_statement_begin__ = 495;
        return stan::math::promote_scalar<fun_return_scalar_t__>(stan::math::not_a_number());
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct log_clogit_denom_functor__ {
    template <typename T2__>
        typename boost::math::tools::promote_args<T2__>::type
    operator()(const int& N_j,
                     const int& D_j,
                     const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& eta_j, std::ostream* pstream__) const {
        return log_clogit_denom(N_j, D_j, eta_j, pstream__);
    }
};

template <typename T0__, typename T1__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type
ll_clogit_lp(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& eta0,
                 const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta1,
                 const std::vector<int>& successes,
                 const std::vector<int>& failures,
                 const std::vector<int>& observations, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 509;
        int J(0);
        (void) J;  // dummy to suppress unused var warning
        stan::math::fill(J, std::numeric_limits<int>::min());
        stan::math::assign(J,num_elements(observations));

        current_statement_begin__ = 510;
        int pos0(0);
        (void) pos0;  // dummy to suppress unused var warning
        stan::math::fill(pos0, std::numeric_limits<int>::min());
        stan::math::assign(pos0,1);

        current_statement_begin__ = 511;
        int pos1(0);
        (void) pos1;  // dummy to suppress unused var warning
        stan::math::fill(pos1, std::numeric_limits<int>::min());
        stan::math::assign(pos1,1);

        current_statement_begin__ = 512;
        validate_non_negative_index("summands", "J", J);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> summands(J);
        stan::math::initialize(summands, DUMMY_VAR__);
        stan::math::fill(summands, DUMMY_VAR__);


        current_statement_begin__ = 513;
        for (int j = 1; j <= J; ++j) {
            {
            current_statement_begin__ = 514;
            int D_g(0);
            (void) D_g;  // dummy to suppress unused var warning
            stan::math::fill(D_g, std::numeric_limits<int>::min());
            stan::math::assign(D_g,get_base1(successes, j, "successes", 1));

            current_statement_begin__ = 515;
            int N_g(0);
            (void) N_g;  // dummy to suppress unused var warning
            stan::math::fill(N_g, std::numeric_limits<int>::min());
            stan::math::assign(N_g,get_base1(observations, j, "observations", 1));

            current_statement_begin__ = 516;
            int F_g(0);
            (void) F_g;  // dummy to suppress unused var warning
            stan::math::fill(F_g, std::numeric_limits<int>::min());
            stan::math::assign(F_g,get_base1(failures, j, "failures", 1));

            current_statement_begin__ = 517;
            validate_non_negative_index("eta_g", "N_g", N_g);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta_g(N_g);
            stan::math::initialize(eta_g, DUMMY_VAR__);
            stan::math::fill(eta_g, DUMMY_VAR__);
            stan::math::assign(eta_g,append_row(segment(eta1, pos1, D_g), segment(eta0, pos0, F_g)));


            current_statement_begin__ = 519;
            stan::model::assign(summands, 
                        stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                        log_clogit_denom(N_g, D_g, eta_g, pstream__), 
                        "assigning variable summands");
            current_statement_begin__ = 520;
            stan::math::assign(pos0, (pos0 + F_g));
            current_statement_begin__ = 521;
            stan::math::assign(pos1, (pos1 + D_g));
            }
        }
        current_statement_begin__ = 523;
        lp_accum__.add((sum(eta1) - sum(summands)));
        current_statement_begin__ = 524;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct ll_clogit_lp_functor__ {
    template <typename T0__, typename T1__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T1__, T_lp__>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& eta0,
                 const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta1,
                 const std::vector<int>& successes,
                 const std::vector<int>& failures,
                 const std::vector<int>& observations, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return ll_clogit_lp(eta0, eta1, successes, failures, observations, lp__, lp_accum__, pstream__);
    }
};

#include <meta_header.hpp>
 class model_stap_bernoulli : public prob_grad {
private:
        int K;
        std::vector<int> N;
        int NN;
        vector_d zbar;
        matrix_d Z0;
        matrix_d Z1;
        std::vector<int> y_0;
        std::vector<int> y_1;
        int Q;
        std::vector<int> log_ar;
        std::vector<int> stap_code;
        int Q_t;
        int Q_s;
        int Q_st;
        int num_s_wei;
        int num_t_wei;
        int M;
        std::vector<vector_d> dists_crs;
        std::vector<vector_d> times_crs;
        std::vector<std::vector<int> > weight_mat;
        std::vector<std::vector<int> > u_s;
        std::vector<std::vector<int> > u_t;
        double max_distance;
        double max_time;
        int has_intercept;
        int link;
        int prior_dist;
        int prior_dist_for_stap;
        int prior_dist_for_intercept;
        int prior_dist_for_aux;
        std::vector<int> prior_dist_for_theta_s;
        std::vector<int> prior_dist_for_theta_t;
        int family;
        int has_weights;
        vector_d weights0;
        vector_d weights1;
        int has_offset;
        vector_d offset0;
        vector_d offset1;
        vector_d prior_scale;
        vector_d prior_scale_for_stap;
        vector_d prior_scale_for_theta_s;
        vector_d prior_scale_for_theta_t;
        double prior_scale_for_intercept;
        double prior_scale_for_aux;
        vector_d prior_mean;
        vector_d prior_mean_for_stap;
        vector_d prior_mean_for_theta_s;
        vector_d prior_mean_for_theta_t;
        double prior_mean_for_intercept;
        double prior_mean_for_aux;
        vector_d prior_df;
        double prior_df_for_intercept;
        double prior_df_for_aux;
        vector_d prior_df_for_theta_s;
        vector_d prior_df_for_theta_t;
        vector_d prior_df_for_stap;
        std::vector<int> num_normals;
        std::vector<int> num_normals_for_stap;
        int t;
        std::vector<int> p;
        std::vector<int> l;
        int q;
        int len_theta_L;
        vector_d shape;
        vector_d scale;
        int len_concentration;
        std::vector<double> concentration;
        int len_regularization;
        std::vector<double> regularization;
        std::vector<int> num_non_zero;
        vector_d w0;
        vector_d w1;
        std::vector<int> v0;
        std::vector<int> v1;
        std::vector<int> u0;
        std::vector<int> u1;
        int special_case;
        double aux;
        std::vector<std::vector<int> > V0;
        std::vector<std::vector<int> > V1;
        int len_z_T;
        int len_var_group;
        int len_rho;
        int is_continuous;
        int pos;
        std::vector<double> del;
        int hs;
public:
    model_stap_bernoulli(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_stap_bernoulli(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        typedef double local_scalar_t__;

        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_stap_bernoulli_namespace::model_stap_bernoulli";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        try {
            // initialize data block variables from context__
            current_statement_begin__ = 529;
            context__.validate_dims("data initialization", "K", "int", context__.to_vec());
            K = int(0);
            vals_i__ = context__.vals_i("K");
            pos__ = 0;
            K = vals_i__[pos__++];
            check_greater_or_equal(function__, "K", K, 0);

            current_statement_begin__ = 530;
            validate_non_negative_index("N", "2", 2);
            context__.validate_dims("data initialization", "N", "int", context__.to_vec(2));
            N = std::vector<int>(2, int(0));
            vals_i__ = context__.vals_i("N");
            pos__ = 0;
            size_t N_k_0_max__ = 2;
            for (size_t k_0__ = 0; k_0__ < N_k_0_max__; ++k_0__) {
                N[k_0__] = vals_i__[pos__++];
            }
            size_t N_i_0_max__ = 2;
            for (size_t i_0__ = 0; i_0__ < N_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "N[i_0__]", N[i_0__], 1);
            }

            current_statement_begin__ = 531;
            context__.validate_dims("data initialization", "NN", "int", context__.to_vec());
            NN = int(0);
            vals_i__ = context__.vals_i("NN");
            pos__ = 0;
            NN = vals_i__[pos__++];
            check_greater_or_equal(function__, "NN", NN, 1);

            current_statement_begin__ = 532;
            validate_non_negative_index("zbar", "K", K);
            context__.validate_dims("data initialization", "zbar", "vector_d", context__.to_vec(K));
            zbar = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("zbar");
            pos__ = 0;
            size_t zbar_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < zbar_j_1_max__; ++j_1__) {
                zbar(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 533;
            validate_non_negative_index("Z0", "get_base1(N, 1, \"N\", 1)", get_base1(N, 1, "N", 1));
            validate_non_negative_index("Z0", "K", K);
            context__.validate_dims("data initialization", "Z0", "matrix_d", context__.to_vec(get_base1(N, 1, "N", 1),K));
            Z0 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(get_base1(N, 1, "N", 1), K);
            vals_r__ = context__.vals_r("Z0");
            pos__ = 0;
            size_t Z0_j_2_max__ = K;
            size_t Z0_j_1_max__ = get_base1(N, 1, "N", 1);
            for (size_t j_2__ = 0; j_2__ < Z0_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < Z0_j_1_max__; ++j_1__) {
                    Z0(j_1__, j_2__) = vals_r__[pos__++];
                }
            }

            current_statement_begin__ = 534;
            validate_non_negative_index("Z1", "get_base1(N, 2, \"N\", 1)", get_base1(N, 2, "N", 1));
            validate_non_negative_index("Z1", "K", K);
            context__.validate_dims("data initialization", "Z1", "matrix_d", context__.to_vec(get_base1(N, 2, "N", 1),K));
            Z1 = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(get_base1(N, 2, "N", 1), K);
            vals_r__ = context__.vals_r("Z1");
            pos__ = 0;
            size_t Z1_j_2_max__ = K;
            size_t Z1_j_1_max__ = get_base1(N, 2, "N", 1);
            for (size_t j_2__ = 0; j_2__ < Z1_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < Z1_j_1_max__; ++j_1__) {
                    Z1(j_1__, j_2__) = vals_r__[pos__++];
                }
            }

            current_statement_begin__ = 535;
            validate_non_negative_index("y_0", "get_base1(N, 1, \"N\", 1)", get_base1(N, 1, "N", 1));
            context__.validate_dims("data initialization", "y_0", "int", context__.to_vec(get_base1(N, 1, "N", 1)));
            y_0 = std::vector<int>(get_base1(N, 1, "N", 1), int(0));
            vals_i__ = context__.vals_i("y_0");
            pos__ = 0;
            size_t y_0_k_0_max__ = get_base1(N, 1, "N", 1);
            for (size_t k_0__ = 0; k_0__ < y_0_k_0_max__; ++k_0__) {
                y_0[k_0__] = vals_i__[pos__++];
            }

            current_statement_begin__ = 536;
            validate_non_negative_index("y_1", "get_base1(N, 2, \"N\", 1)", get_base1(N, 2, "N", 1));
            context__.validate_dims("data initialization", "y_1", "int", context__.to_vec(get_base1(N, 2, "N", 1)));
            y_1 = std::vector<int>(get_base1(N, 2, "N", 1), int(0));
            vals_i__ = context__.vals_i("y_1");
            pos__ = 0;
            size_t y_1_k_0_max__ = get_base1(N, 2, "N", 1);
            for (size_t k_0__ = 0; k_0__ < y_1_k_0_max__; ++k_0__) {
                y_1[k_0__] = vals_i__[pos__++];
            }

            current_statement_begin__ = 539;
            context__.validate_dims("data initialization", "Q", "int", context__.to_vec());
            Q = int(0);
            vals_i__ = context__.vals_i("Q");
            pos__ = 0;
            Q = vals_i__[pos__++];
            check_greater_or_equal(function__, "Q", Q, 0);

            current_statement_begin__ = 540;
            validate_non_negative_index("log_ar", "Q", Q);
            context__.validate_dims("data initialization", "log_ar", "int", context__.to_vec(Q));
            log_ar = std::vector<int>(Q, int(0));
            vals_i__ = context__.vals_i("log_ar");
            pos__ = 0;
            size_t log_ar_k_0_max__ = Q;
            for (size_t k_0__ = 0; k_0__ < log_ar_k_0_max__; ++k_0__) {
                log_ar[k_0__] = vals_i__[pos__++];
            }
            size_t log_ar_i_0_max__ = Q;
            for (size_t i_0__ = 0; i_0__ < log_ar_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "log_ar[i_0__]", log_ar[i_0__], 0);
                check_less_or_equal(function__, "log_ar[i_0__]", log_ar[i_0__], 1);
            }

            current_statement_begin__ = 541;
            validate_non_negative_index("stap_code", "Q", Q);
            context__.validate_dims("data initialization", "stap_code", "int", context__.to_vec(Q));
            stap_code = std::vector<int>(Q, int(0));
            vals_i__ = context__.vals_i("stap_code");
            pos__ = 0;
            size_t stap_code_k_0_max__ = Q;
            for (size_t k_0__ = 0; k_0__ < stap_code_k_0_max__; ++k_0__) {
                stap_code[k_0__] = vals_i__[pos__++];
            }
            size_t stap_code_i_0_max__ = Q;
            for (size_t i_0__ = 0; i_0__ < stap_code_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "stap_code[i_0__]", stap_code[i_0__], 0);
                check_less_or_equal(function__, "stap_code[i_0__]", stap_code[i_0__], 2);
            }

            current_statement_begin__ = 542;
            context__.validate_dims("data initialization", "Q_t", "int", context__.to_vec());
            Q_t = int(0);
            vals_i__ = context__.vals_i("Q_t");
            pos__ = 0;
            Q_t = vals_i__[pos__++];
            check_greater_or_equal(function__, "Q_t", Q_t, 0);

            current_statement_begin__ = 543;
            context__.validate_dims("data initialization", "Q_s", "int", context__.to_vec());
            Q_s = int(0);
            vals_i__ = context__.vals_i("Q_s");
            pos__ = 0;
            Q_s = vals_i__[pos__++];
            check_greater_or_equal(function__, "Q_s", Q_s, 0);

            current_statement_begin__ = 544;
            context__.validate_dims("data initialization", "Q_st", "int", context__.to_vec());
            Q_st = int(0);
            vals_i__ = context__.vals_i("Q_st");
            pos__ = 0;
            Q_st = vals_i__[pos__++];
            check_greater_or_equal(function__, "Q_st", Q_st, 0);
            check_less_or_equal(function__, "Q_st", Q_st, ((Q - Q_t) - Q_s));

            current_statement_begin__ = 545;
            context__.validate_dims("data initialization", "num_s_wei", "int", context__.to_vec());
            num_s_wei = int(0);
            vals_i__ = context__.vals_i("num_s_wei");
            pos__ = 0;
            num_s_wei = vals_i__[pos__++];
            check_greater_or_equal(function__, "num_s_wei", num_s_wei, 0);

            current_statement_begin__ = 546;
            context__.validate_dims("data initialization", "num_t_wei", "int", context__.to_vec());
            num_t_wei = int(0);
            vals_i__ = context__.vals_i("num_t_wei");
            pos__ = 0;
            num_t_wei = vals_i__[pos__++];
            check_greater_or_equal(function__, "num_t_wei", num_t_wei, 0);

            current_statement_begin__ = 547;
            context__.validate_dims("data initialization", "M", "int", context__.to_vec());
            M = int(0);
            vals_i__ = context__.vals_i("M");
            pos__ = 0;
            M = vals_i__[pos__++];
            check_greater_or_equal(function__, "M", M, 0);

            current_statement_begin__ = 548;
            validate_non_negative_index("dists_crs", "(logical_gt((Q_s + Q_st), 0) ? M : 0 )", (logical_gt((Q_s + Q_st), 0) ? M : 0 ));
            validate_non_negative_index("dists_crs", "(Q_s + Q_st)", (Q_s + Q_st));
            context__.validate_dims("data initialization", "dists_crs", "vector_d", context__.to_vec((Q_s + Q_st),(logical_gt((Q_s + Q_st), 0) ? M : 0 )));
            dists_crs = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >((Q_s + Q_st), Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_s + Q_st), 0) ? M : 0 )));
            vals_r__ = context__.vals_r("dists_crs");
            pos__ = 0;
            size_t dists_crs_j_1_max__ = (logical_gt((Q_s + Q_st), 0) ? M : 0 );
            size_t dists_crs_k_0_max__ = (Q_s + Q_st);
            for (size_t j_1__ = 0; j_1__ < dists_crs_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < dists_crs_k_0_max__; ++k_0__) {
                    dists_crs[k_0__](j_1__) = vals_r__[pos__++];
                }
            }
            size_t dists_crs_i_0_max__ = (Q_s + Q_st);
            for (size_t i_0__ = 0; i_0__ < dists_crs_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "dists_crs[i_0__]", dists_crs[i_0__], 0);
            }

            current_statement_begin__ = 549;
            validate_non_negative_index("times_crs", "(logical_gt((Q_t + Q_st), 0) ? M : 0 )", (logical_gt((Q_t + Q_st), 0) ? M : 0 ));
            validate_non_negative_index("times_crs", "(Q_t + Q_st)", (Q_t + Q_st));
            context__.validate_dims("data initialization", "times_crs", "vector_d", context__.to_vec((Q_t + Q_st),(logical_gt((Q_t + Q_st), 0) ? M : 0 )));
            times_crs = std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> >((Q_t + Q_st), Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_t + Q_st), 0) ? M : 0 )));
            vals_r__ = context__.vals_r("times_crs");
            pos__ = 0;
            size_t times_crs_j_1_max__ = (logical_gt((Q_t + Q_st), 0) ? M : 0 );
            size_t times_crs_k_0_max__ = (Q_t + Q_st);
            for (size_t j_1__ = 0; j_1__ < times_crs_j_1_max__; ++j_1__) {
                for (size_t k_0__ = 0; k_0__ < times_crs_k_0_max__; ++k_0__) {
                    times_crs[k_0__](j_1__) = vals_r__[pos__++];
                }
            }
            size_t times_crs_i_0_max__ = (Q_t + Q_st);
            for (size_t i_0__ = 0; i_0__ < times_crs_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "times_crs[i_0__]", times_crs[i_0__], 0);
            }

            current_statement_begin__ = 550;
            validate_non_negative_index("weight_mat", "Q", Q);
            validate_non_negative_index("weight_mat", "2", 2);
            context__.validate_dims("data initialization", "weight_mat", "int", context__.to_vec(Q,2));
            weight_mat = std::vector<std::vector<int> >(Q, std::vector<int>(2, int(0)));
            vals_i__ = context__.vals_i("weight_mat");
            pos__ = 0;
            size_t weight_mat_k_0_max__ = Q;
            size_t weight_mat_k_1_max__ = 2;
            for (size_t k_1__ = 0; k_1__ < weight_mat_k_1_max__; ++k_1__) {
                for (size_t k_0__ = 0; k_0__ < weight_mat_k_0_max__; ++k_0__) {
                    weight_mat[k_0__][k_1__] = vals_i__[pos__++];
                }
            }
            size_t weight_mat_i_0_max__ = Q;
            size_t weight_mat_i_1_max__ = 2;
            for (size_t i_0__ = 0; i_0__ < weight_mat_i_0_max__; ++i_0__) {
                for (size_t i_1__ = 0; i_1__ < weight_mat_i_1_max__; ++i_1__) {
                    check_greater_or_equal(function__, "weight_mat[i_0__][i_1__]", weight_mat[i_0__][i_1__], 0);
                }
            }

            current_statement_begin__ = 552;
            validate_non_negative_index("u_s", "(logical_gt((Q_s + Q_st), 0) ? NN : 0 )", (logical_gt((Q_s + Q_st), 0) ? NN : 0 ));
            validate_non_negative_index("u_s", "(logical_gt((Q_s + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 )", (logical_gt((Q_s + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 ));
            context__.validate_dims("data initialization", "u_s", "int", context__.to_vec((logical_gt((Q_s + Q_st), 0) ? NN : 0 ),(logical_gt((Q_s + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 )));
            u_s = std::vector<std::vector<int> >((logical_gt((Q_s + Q_st), 0) ? NN : 0 ), std::vector<int>((logical_gt((Q_s + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 ), int(0)));
            vals_i__ = context__.vals_i("u_s");
            pos__ = 0;
            size_t u_s_k_0_max__ = (logical_gt((Q_s + Q_st), 0) ? NN : 0 );
            size_t u_s_k_1_max__ = (logical_gt((Q_s + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 );
            for (size_t k_1__ = 0; k_1__ < u_s_k_1_max__; ++k_1__) {
                for (size_t k_0__ = 0; k_0__ < u_s_k_0_max__; ++k_0__) {
                    u_s[k_0__][k_1__] = vals_i__[pos__++];
                }
            }

            current_statement_begin__ = 553;
            validate_non_negative_index("u_t", "(logical_gt((Q_t + Q_st), 0) ? NN : 0 )", (logical_gt((Q_t + Q_st), 0) ? NN : 0 ));
            validate_non_negative_index("u_t", "(logical_gt((Q_t + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 )", (logical_gt((Q_t + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 ));
            context__.validate_dims("data initialization", "u_t", "int", context__.to_vec((logical_gt((Q_t + Q_st), 0) ? NN : 0 ),(logical_gt((Q_t + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 )));
            u_t = std::vector<std::vector<int> >((logical_gt((Q_t + Q_st), 0) ? NN : 0 ), std::vector<int>((logical_gt((Q_t + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 ), int(0)));
            vals_i__ = context__.vals_i("u_t");
            pos__ = 0;
            size_t u_t_k_0_max__ = (logical_gt((Q_t + Q_st), 0) ? NN : 0 );
            size_t u_t_k_1_max__ = (logical_gt((Q_t + Q_st), 0) ? ((Q_s + Q_st) * 2) : 0 );
            for (size_t k_1__ = 0; k_1__ < u_t_k_1_max__; ++k_1__) {
                for (size_t k_0__ = 0; k_0__ < u_t_k_0_max__; ++k_0__) {
                    u_t[k_0__][k_1__] = vals_i__[pos__++];
                }
            }

            current_statement_begin__ = 554;
            context__.validate_dims("data initialization", "max_distance", "double", context__.to_vec());
            max_distance = double(0);
            vals_r__ = context__.vals_r("max_distance");
            pos__ = 0;
            max_distance = vals_r__[pos__++];
            check_greater_or_equal(function__, "max_distance", max_distance, 0);

            current_statement_begin__ = 555;
            context__.validate_dims("data initialization", "max_time", "double", context__.to_vec());
            max_time = double(0);
            vals_r__ = context__.vals_r("max_time");
            pos__ = 0;
            max_time = vals_r__[pos__++];
            check_greater_or_equal(function__, "max_time", max_time, 0);

            current_statement_begin__ = 560;
            context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
            has_intercept = int(0);
            vals_i__ = context__.vals_i("has_intercept");
            pos__ = 0;
            has_intercept = vals_i__[pos__++];
            check_greater_or_equal(function__, "has_intercept", has_intercept, 0);
            check_less_or_equal(function__, "has_intercept", has_intercept, 1);

            current_statement_begin__ = 563;
            context__.validate_dims("data initialization", "link", "int", context__.to_vec());
            link = int(0);
            vals_i__ = context__.vals_i("link");
            pos__ = 0;
            link = vals_i__[pos__++];
            check_greater_or_equal(function__, "link", link, 1);

            current_statement_begin__ = 567;
            context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
            prior_dist = int(0);
            vals_i__ = context__.vals_i("prior_dist");
            pos__ = 0;
            prior_dist = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist", prior_dist, 0);
            check_less_or_equal(function__, "prior_dist", prior_dist, 7);

            current_statement_begin__ = 568;
            context__.validate_dims("data initialization", "prior_dist_for_stap", "int", context__.to_vec());
            prior_dist_for_stap = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_stap");
            pos__ = 0;
            prior_dist_for_stap = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist_for_stap", prior_dist_for_stap, 0);
            check_less_or_equal(function__, "prior_dist_for_stap", prior_dist_for_stap, 7);

            current_statement_begin__ = 569;
            context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
            prior_dist_for_intercept = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_intercept");
            pos__ = 0;
            prior_dist_for_intercept = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist_for_intercept", prior_dist_for_intercept, 0);
            check_less_or_equal(function__, "prior_dist_for_intercept", prior_dist_for_intercept, 2);

            current_statement_begin__ = 572;
            context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
            prior_dist_for_aux = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_aux");
            pos__ = 0;
            prior_dist_for_aux = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist_for_aux", prior_dist_for_aux, 0);
            check_less_or_equal(function__, "prior_dist_for_aux", prior_dist_for_aux, 3);

            current_statement_begin__ = 575;
            validate_non_negative_index("prior_dist_for_theta_s", "(logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )", (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_dist_for_theta_s", "int", context__.to_vec((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )));
            prior_dist_for_theta_s = std::vector<int>((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ), int(0));
            vals_i__ = context__.vals_i("prior_dist_for_theta_s");
            pos__ = 0;
            size_t prior_dist_for_theta_s_k_0_max__ = (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 );
            for (size_t k_0__ = 0; k_0__ < prior_dist_for_theta_s_k_0_max__; ++k_0__) {
                prior_dist_for_theta_s[k_0__] = vals_i__[pos__++];
            }
            size_t prior_dist_for_theta_s_i_0_max__ = (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 );
            for (size_t i_0__ = 0; i_0__ < prior_dist_for_theta_s_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "prior_dist_for_theta_s[i_0__]", prior_dist_for_theta_s[i_0__], 0);
                check_less_or_equal(function__, "prior_dist_for_theta_s[i_0__]", prior_dist_for_theta_s[i_0__], 9);
            }

            current_statement_begin__ = 576;
            validate_non_negative_index("prior_dist_for_theta_t", "(logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )", (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_dist_for_theta_t", "int", context__.to_vec((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )));
            prior_dist_for_theta_t = std::vector<int>((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ), int(0));
            vals_i__ = context__.vals_i("prior_dist_for_theta_t");
            pos__ = 0;
            size_t prior_dist_for_theta_t_k_0_max__ = (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 );
            for (size_t k_0__ = 0; k_0__ < prior_dist_for_theta_t_k_0_max__; ++k_0__) {
                prior_dist_for_theta_t[k_0__] = vals_i__[pos__++];
            }
            size_t prior_dist_for_theta_t_i_0_max__ = (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 );
            for (size_t i_0__ = 0; i_0__ < prior_dist_for_theta_t_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "prior_dist_for_theta_t[i_0__]", prior_dist_for_theta_t[i_0__], 0);
                check_less_or_equal(function__, "prior_dist_for_theta_t[i_0__]", prior_dist_for_theta_t[i_0__], 9);
            }

            current_statement_begin__ = 578;
            context__.validate_dims("data initialization", "family", "int", context__.to_vec());
            family = int(0);
            vals_i__ = context__.vals_i("family");
            pos__ = 0;
            family = vals_i__[pos__++];
            check_greater_or_equal(function__, "family", family, 5);
            check_less_or_equal(function__, "family", family, 5);

            current_statement_begin__ = 581;
            context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
            has_weights = int(0);
            vals_i__ = context__.vals_i("has_weights");
            pos__ = 0;
            has_weights = vals_i__[pos__++];
            check_greater_or_equal(function__, "has_weights", has_weights, 0);
            check_less_or_equal(function__, "has_weights", has_weights, 1);

            current_statement_begin__ = 582;
            validate_non_negative_index("weights0", "(has_weights ? get_base1(N, 1, \"N\", 1) : 0 )", (has_weights ? get_base1(N, 1, "N", 1) : 0 ));
            context__.validate_dims("data initialization", "weights0", "vector_d", context__.to_vec((has_weights ? get_base1(N, 1, "N", 1) : 0 )));
            weights0 = Eigen::Matrix<double, Eigen::Dynamic, 1>((has_weights ? get_base1(N, 1, "N", 1) : 0 ));
            vals_r__ = context__.vals_r("weights0");
            pos__ = 0;
            size_t weights0_j_1_max__ = (has_weights ? get_base1(N, 1, "N", 1) : 0 );
            for (size_t j_1__ = 0; j_1__ < weights0_j_1_max__; ++j_1__) {
                weights0(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 583;
            validate_non_negative_index("weights1", "(has_weights ? get_base1(N, 2, \"N\", 1) : 0 )", (has_weights ? get_base1(N, 2, "N", 1) : 0 ));
            context__.validate_dims("data initialization", "weights1", "vector_d", context__.to_vec((has_weights ? get_base1(N, 2, "N", 1) : 0 )));
            weights1 = Eigen::Matrix<double, Eigen::Dynamic, 1>((has_weights ? get_base1(N, 2, "N", 1) : 0 ));
            vals_r__ = context__.vals_r("weights1");
            pos__ = 0;
            size_t weights1_j_1_max__ = (has_weights ? get_base1(N, 2, "N", 1) : 0 );
            for (size_t j_1__ = 0; j_1__ < weights1_j_1_max__; ++j_1__) {
                weights1(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 586;
            context__.validate_dims("data initialization", "has_offset", "int", context__.to_vec());
            has_offset = int(0);
            vals_i__ = context__.vals_i("has_offset");
            pos__ = 0;
            has_offset = vals_i__[pos__++];
            check_greater_or_equal(function__, "has_offset", has_offset, 0);
            check_less_or_equal(function__, "has_offset", has_offset, 1);

            current_statement_begin__ = 587;
            validate_non_negative_index("offset0", "(has_offset ? get_base1(N, 1, \"N\", 1) : 0 )", (has_offset ? get_base1(N, 1, "N", 1) : 0 ));
            context__.validate_dims("data initialization", "offset0", "vector_d", context__.to_vec((has_offset ? get_base1(N, 1, "N", 1) : 0 )));
            offset0 = Eigen::Matrix<double, Eigen::Dynamic, 1>((has_offset ? get_base1(N, 1, "N", 1) : 0 ));
            vals_r__ = context__.vals_r("offset0");
            pos__ = 0;
            size_t offset0_j_1_max__ = (has_offset ? get_base1(N, 1, "N", 1) : 0 );
            for (size_t j_1__ = 0; j_1__ < offset0_j_1_max__; ++j_1__) {
                offset0(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 588;
            validate_non_negative_index("offset1", "(has_offset ? get_base1(N, 2, \"N\", 1) : 0 )", (has_offset ? get_base1(N, 2, "N", 1) : 0 ));
            context__.validate_dims("data initialization", "offset1", "vector_d", context__.to_vec((has_offset ? get_base1(N, 2, "N", 1) : 0 )));
            offset1 = Eigen::Matrix<double, Eigen::Dynamic, 1>((has_offset ? get_base1(N, 2, "N", 1) : 0 ));
            vals_r__ = context__.vals_r("offset1");
            pos__ = 0;
            size_t offset1_j_1_max__ = (has_offset ? get_base1(N, 2, "N", 1) : 0 );
            for (size_t j_1__ = 0; j_1__ < offset1_j_1_max__; ++j_1__) {
                offset1(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 593;
            validate_non_negative_index("prior_scale", "K", K);
            context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
            prior_scale = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("prior_scale");
            pos__ = 0;
            size_t prior_scale_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < prior_scale_j_1_max__; ++j_1__) {
                prior_scale(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_scale", prior_scale, 0);

            current_statement_begin__ = 594;
            validate_non_negative_index("prior_scale_for_stap", "Q", Q);
            context__.validate_dims("data initialization", "prior_scale_for_stap", "vector_d", context__.to_vec(Q));
            prior_scale_for_stap = Eigen::Matrix<double, Eigen::Dynamic, 1>(Q);
            vals_r__ = context__.vals_r("prior_scale_for_stap");
            pos__ = 0;
            size_t prior_scale_for_stap_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < prior_scale_for_stap_j_1_max__; ++j_1__) {
                prior_scale_for_stap(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_scale_for_stap", prior_scale_for_stap, 0);

            current_statement_begin__ = 595;
            validate_non_negative_index("prior_scale_for_theta_s", "(logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )", (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_scale_for_theta_s", "vector_d", context__.to_vec((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )));
            prior_scale_for_theta_s = Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            vals_r__ = context__.vals_r("prior_scale_for_theta_s");
            pos__ = 0;
            size_t prior_scale_for_theta_s_j_1_max__ = (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 );
            for (size_t j_1__ = 0; j_1__ < prior_scale_for_theta_s_j_1_max__; ++j_1__) {
                prior_scale_for_theta_s(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_scale_for_theta_s", prior_scale_for_theta_s, 0);

            current_statement_begin__ = 596;
            validate_non_negative_index("prior_scale_for_theta_t", "(logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )", (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_scale_for_theta_t", "vector_d", context__.to_vec((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )));
            prior_scale_for_theta_t = Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            vals_r__ = context__.vals_r("prior_scale_for_theta_t");
            pos__ = 0;
            size_t prior_scale_for_theta_t_j_1_max__ = (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 );
            for (size_t j_1__ = 0; j_1__ < prior_scale_for_theta_t_j_1_max__; ++j_1__) {
                prior_scale_for_theta_t(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_scale_for_theta_t", prior_scale_for_theta_t, 0);

            current_statement_begin__ = 597;
            context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
            prior_scale_for_intercept = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_intercept");
            pos__ = 0;
            prior_scale_for_intercept = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_scale_for_intercept", prior_scale_for_intercept, 0);

            current_statement_begin__ = 598;
            context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
            prior_scale_for_aux = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_aux");
            pos__ = 0;
            prior_scale_for_aux = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_scale_for_aux", prior_scale_for_aux, 0);

            current_statement_begin__ = 599;
            validate_non_negative_index("prior_mean", "K", K);
            context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
            prior_mean = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("prior_mean");
            pos__ = 0;
            size_t prior_mean_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < prior_mean_j_1_max__; ++j_1__) {
                prior_mean(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 600;
            validate_non_negative_index("prior_mean_for_stap", "Q", Q);
            context__.validate_dims("data initialization", "prior_mean_for_stap", "vector_d", context__.to_vec(Q));
            prior_mean_for_stap = Eigen::Matrix<double, Eigen::Dynamic, 1>(Q);
            vals_r__ = context__.vals_r("prior_mean_for_stap");
            pos__ = 0;
            size_t prior_mean_for_stap_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < prior_mean_for_stap_j_1_max__; ++j_1__) {
                prior_mean_for_stap(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 601;
            validate_non_negative_index("prior_mean_for_theta_s", "(logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )", (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_mean_for_theta_s", "vector_d", context__.to_vec((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )));
            prior_mean_for_theta_s = Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            vals_r__ = context__.vals_r("prior_mean_for_theta_s");
            pos__ = 0;
            size_t prior_mean_for_theta_s_j_1_max__ = (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 );
            for (size_t j_1__ = 0; j_1__ < prior_mean_for_theta_s_j_1_max__; ++j_1__) {
                prior_mean_for_theta_s(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 602;
            validate_non_negative_index("prior_mean_for_theta_t", "(logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )", (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_mean_for_theta_t", "vector_d", context__.to_vec((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )));
            prior_mean_for_theta_t = Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            vals_r__ = context__.vals_r("prior_mean_for_theta_t");
            pos__ = 0;
            size_t prior_mean_for_theta_t_j_1_max__ = (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 );
            for (size_t j_1__ = 0; j_1__ < prior_mean_for_theta_t_j_1_max__; ++j_1__) {
                prior_mean_for_theta_t(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 603;
            context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
            prior_mean_for_intercept = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_intercept");
            pos__ = 0;
            prior_mean_for_intercept = vals_r__[pos__++];

            current_statement_begin__ = 604;
            context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
            prior_mean_for_aux = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_aux");
            pos__ = 0;
            prior_mean_for_aux = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_mean_for_aux", prior_mean_for_aux, 0);

            current_statement_begin__ = 605;
            validate_non_negative_index("prior_df", "K", K);
            context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
            prior_df = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("prior_df");
            pos__ = 0;
            size_t prior_df_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < prior_df_j_1_max__; ++j_1__) {
                prior_df(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_df", prior_df, 0);

            current_statement_begin__ = 606;
            context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
            prior_df_for_intercept = double(0);
            vals_r__ = context__.vals_r("prior_df_for_intercept");
            pos__ = 0;
            prior_df_for_intercept = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_df_for_intercept", prior_df_for_intercept, 0);

            current_statement_begin__ = 607;
            context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
            prior_df_for_aux = double(0);
            vals_r__ = context__.vals_r("prior_df_for_aux");
            pos__ = 0;
            prior_df_for_aux = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_df_for_aux", prior_df_for_aux, 0);

            current_statement_begin__ = 608;
            validate_non_negative_index("prior_df_for_theta_s", "(logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )", (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_df_for_theta_s", "vector_d", context__.to_vec((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 )));
            prior_df_for_theta_s = Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 ));
            vals_r__ = context__.vals_r("prior_df_for_theta_s");
            pos__ = 0;
            size_t prior_df_for_theta_s_j_1_max__ = (logical_gt((Q_s + Q_st), 0) ? (Q_s + Q_st) : 0 );
            for (size_t j_1__ = 0; j_1__ < prior_df_for_theta_s_j_1_max__; ++j_1__) {
                prior_df_for_theta_s(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_df_for_theta_s", prior_df_for_theta_s, 0);

            current_statement_begin__ = 609;
            validate_non_negative_index("prior_df_for_theta_t", "(logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )", (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            context__.validate_dims("data initialization", "prior_df_for_theta_t", "vector_d", context__.to_vec((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 )));
            prior_df_for_theta_t = Eigen::Matrix<double, Eigen::Dynamic, 1>((logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 ));
            vals_r__ = context__.vals_r("prior_df_for_theta_t");
            pos__ = 0;
            size_t prior_df_for_theta_t_j_1_max__ = (logical_gt((Q_t + Q_st), 0) ? (Q_t + Q_st) : 0 );
            for (size_t j_1__ = 0; j_1__ < prior_df_for_theta_t_j_1_max__; ++j_1__) {
                prior_df_for_theta_t(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_df_for_theta_t", prior_df_for_theta_t, 0);

            current_statement_begin__ = 610;
            validate_non_negative_index("prior_df_for_stap", "Q", Q);
            context__.validate_dims("data initialization", "prior_df_for_stap", "vector_d", context__.to_vec(Q));
            prior_df_for_stap = Eigen::Matrix<double, Eigen::Dynamic, 1>(Q);
            vals_r__ = context__.vals_r("prior_df_for_stap");
            pos__ = 0;
            size_t prior_df_for_stap_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < prior_df_for_stap_j_1_max__; ++j_1__) {
                prior_df_for_stap(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_df_for_stap", prior_df_for_stap, 0);

            current_statement_begin__ = 612;
            validate_non_negative_index("num_normals", "(logical_eq(prior_dist, 7) ? K : 0 )", (logical_eq(prior_dist, 7) ? K : 0 ));
            context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist, 7) ? K : 0 )));
            num_normals = std::vector<int>((logical_eq(prior_dist, 7) ? K : 0 ), int(0));
            vals_i__ = context__.vals_i("num_normals");
            pos__ = 0;
            size_t num_normals_k_0_max__ = (logical_eq(prior_dist, 7) ? K : 0 );
            for (size_t k_0__ = 0; k_0__ < num_normals_k_0_max__; ++k_0__) {
                num_normals[k_0__] = vals_i__[pos__++];
            }
            size_t num_normals_i_0_max__ = (logical_eq(prior_dist, 7) ? K : 0 );
            for (size_t i_0__ = 0; i_0__ < num_normals_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "num_normals[i_0__]", num_normals[i_0__], 2);
            }

            current_statement_begin__ = 613;
            validate_non_negative_index("num_normals_for_stap", "(logical_eq(prior_dist_for_stap, 7) ? Q : 0 )", (logical_eq(prior_dist_for_stap, 7) ? Q : 0 ));
            context__.validate_dims("data initialization", "num_normals_for_stap", "int", context__.to_vec((logical_eq(prior_dist_for_stap, 7) ? Q : 0 )));
            num_normals_for_stap = std::vector<int>((logical_eq(prior_dist_for_stap, 7) ? Q : 0 ), int(0));
            vals_i__ = context__.vals_i("num_normals_for_stap");
            pos__ = 0;
            size_t num_normals_for_stap_k_0_max__ = (logical_eq(prior_dist_for_stap, 7) ? Q : 0 );
            for (size_t k_0__ = 0; k_0__ < num_normals_for_stap_k_0_max__; ++k_0__) {
                num_normals_for_stap[k_0__] = vals_i__[pos__++];
            }
            size_t num_normals_for_stap_i_0_max__ = (logical_eq(prior_dist_for_stap, 7) ? Q : 0 );
            for (size_t i_0__ = 0; i_0__ < num_normals_for_stap_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "num_normals_for_stap[i_0__]", num_normals_for_stap[i_0__], 2);
            }

            current_statement_begin__ = 617;
            context__.validate_dims("data initialization", "t", "int", context__.to_vec());
            t = int(0);
            vals_i__ = context__.vals_i("t");
            pos__ = 0;
            t = vals_i__[pos__++];
            check_greater_or_equal(function__, "t", t, 0);

            current_statement_begin__ = 618;
            validate_non_negative_index("p", "t", t);
            context__.validate_dims("data initialization", "p", "int", context__.to_vec(t));
            p = std::vector<int>(t, int(0));
            vals_i__ = context__.vals_i("p");
            pos__ = 0;
            size_t p_k_0_max__ = t;
            for (size_t k_0__ = 0; k_0__ < p_k_0_max__; ++k_0__) {
                p[k_0__] = vals_i__[pos__++];
            }
            size_t p_i_0_max__ = t;
            for (size_t i_0__ = 0; i_0__ < p_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "p[i_0__]", p[i_0__], 1);
            }

            current_statement_begin__ = 619;
            validate_non_negative_index("l", "t", t);
            context__.validate_dims("data initialization", "l", "int", context__.to_vec(t));
            l = std::vector<int>(t, int(0));
            vals_i__ = context__.vals_i("l");
            pos__ = 0;
            size_t l_k_0_max__ = t;
            for (size_t k_0__ = 0; k_0__ < l_k_0_max__; ++k_0__) {
                l[k_0__] = vals_i__[pos__++];
            }
            size_t l_i_0_max__ = t;
            for (size_t i_0__ = 0; i_0__ < l_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "l[i_0__]", l[i_0__], 1);
            }

            current_statement_begin__ = 620;
            context__.validate_dims("data initialization", "q", "int", context__.to_vec());
            q = int(0);
            vals_i__ = context__.vals_i("q");
            pos__ = 0;
            q = vals_i__[pos__++];
            check_greater_or_equal(function__, "q", q, 0);

            current_statement_begin__ = 621;
            context__.validate_dims("data initialization", "len_theta_L", "int", context__.to_vec());
            len_theta_L = int(0);
            vals_i__ = context__.vals_i("len_theta_L");
            pos__ = 0;
            len_theta_L = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_theta_L", len_theta_L, 0);

            current_statement_begin__ = 624;
            validate_non_negative_index("shape", "t", t);
            context__.validate_dims("data initialization", "shape", "vector_d", context__.to_vec(t));
            shape = Eigen::Matrix<double, Eigen::Dynamic, 1>(t);
            vals_r__ = context__.vals_r("shape");
            pos__ = 0;
            size_t shape_j_1_max__ = t;
            for (size_t j_1__ = 0; j_1__ < shape_j_1_max__; ++j_1__) {
                shape(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "shape", shape, 0);

            current_statement_begin__ = 625;
            validate_non_negative_index("scale", "t", t);
            context__.validate_dims("data initialization", "scale", "vector_d", context__.to_vec(t));
            scale = Eigen::Matrix<double, Eigen::Dynamic, 1>(t);
            vals_r__ = context__.vals_r("scale");
            pos__ = 0;
            size_t scale_j_1_max__ = t;
            for (size_t j_1__ = 0; j_1__ < scale_j_1_max__; ++j_1__) {
                scale(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "scale", scale, 0);

            current_statement_begin__ = 626;
            context__.validate_dims("data initialization", "len_concentration", "int", context__.to_vec());
            len_concentration = int(0);
            vals_i__ = context__.vals_i("len_concentration");
            pos__ = 0;
            len_concentration = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_concentration", len_concentration, 0);

            current_statement_begin__ = 627;
            validate_non_negative_index("concentration", "len_concentration", len_concentration);
            context__.validate_dims("data initialization", "concentration", "double", context__.to_vec(len_concentration));
            concentration = std::vector<double>(len_concentration, double(0));
            vals_r__ = context__.vals_r("concentration");
            pos__ = 0;
            size_t concentration_k_0_max__ = len_concentration;
            for (size_t k_0__ = 0; k_0__ < concentration_k_0_max__; ++k_0__) {
                concentration[k_0__] = vals_r__[pos__++];
            }
            size_t concentration_i_0_max__ = len_concentration;
            for (size_t i_0__ = 0; i_0__ < concentration_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "concentration[i_0__]", concentration[i_0__], 0);
            }

            current_statement_begin__ = 628;
            context__.validate_dims("data initialization", "len_regularization", "int", context__.to_vec());
            len_regularization = int(0);
            vals_i__ = context__.vals_i("len_regularization");
            pos__ = 0;
            len_regularization = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_regularization", len_regularization, 0);

            current_statement_begin__ = 629;
            validate_non_negative_index("regularization", "len_regularization", len_regularization);
            context__.validate_dims("data initialization", "regularization", "double", context__.to_vec(len_regularization));
            regularization = std::vector<double>(len_regularization, double(0));
            vals_r__ = context__.vals_r("regularization");
            pos__ = 0;
            size_t regularization_k_0_max__ = len_regularization;
            for (size_t k_0__ = 0; k_0__ < regularization_k_0_max__; ++k_0__) {
                regularization[k_0__] = vals_r__[pos__++];
            }
            size_t regularization_i_0_max__ = len_regularization;
            for (size_t i_0__ = 0; i_0__ < regularization_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "regularization[i_0__]", regularization[i_0__], 0);
            }

            current_statement_begin__ = 632;
            validate_non_negative_index("num_non_zero", "2", 2);
            context__.validate_dims("data initialization", "num_non_zero", "int", context__.to_vec(2));
            num_non_zero = std::vector<int>(2, int(0));
            vals_i__ = context__.vals_i("num_non_zero");
            pos__ = 0;
            size_t num_non_zero_k_0_max__ = 2;
            for (size_t k_0__ = 0; k_0__ < num_non_zero_k_0_max__; ++k_0__) {
                num_non_zero[k_0__] = vals_i__[pos__++];
            }
            size_t num_non_zero_i_0_max__ = 2;
            for (size_t i_0__ = 0; i_0__ < num_non_zero_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "num_non_zero[i_0__]", num_non_zero[i_0__], 0);
            }

            current_statement_begin__ = 633;
            validate_non_negative_index("w0", "get_base1(num_non_zero, 1, \"num_non_zero\", 1)", get_base1(num_non_zero, 1, "num_non_zero", 1));
            context__.validate_dims("data initialization", "w0", "vector_d", context__.to_vec(get_base1(num_non_zero, 1, "num_non_zero", 1)));
            w0 = Eigen::Matrix<double, Eigen::Dynamic, 1>(get_base1(num_non_zero, 1, "num_non_zero", 1));
            vals_r__ = context__.vals_r("w0");
            pos__ = 0;
            size_t w0_j_1_max__ = get_base1(num_non_zero, 1, "num_non_zero", 1);
            for (size_t j_1__ = 0; j_1__ < w0_j_1_max__; ++j_1__) {
                w0(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 634;
            validate_non_negative_index("w1", "get_base1(num_non_zero, 2, \"num_non_zero\", 1)", get_base1(num_non_zero, 2, "num_non_zero", 1));
            context__.validate_dims("data initialization", "w1", "vector_d", context__.to_vec(get_base1(num_non_zero, 2, "num_non_zero", 1)));
            w1 = Eigen::Matrix<double, Eigen::Dynamic, 1>(get_base1(num_non_zero, 2, "num_non_zero", 1));
            vals_r__ = context__.vals_r("w1");
            pos__ = 0;
            size_t w1_j_1_max__ = get_base1(num_non_zero, 2, "num_non_zero", 1);
            for (size_t j_1__ = 0; j_1__ < w1_j_1_max__; ++j_1__) {
                w1(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 635;
            validate_non_negative_index("v0", "get_base1(num_non_zero, 1, \"num_non_zero\", 1)", get_base1(num_non_zero, 1, "num_non_zero", 1));
            context__.validate_dims("data initialization", "v0", "int", context__.to_vec(get_base1(num_non_zero, 1, "num_non_zero", 1)));
            v0 = std::vector<int>(get_base1(num_non_zero, 1, "num_non_zero", 1), int(0));
            vals_i__ = context__.vals_i("v0");
            pos__ = 0;
            size_t v0_k_0_max__ = get_base1(num_non_zero, 1, "num_non_zero", 1);
            for (size_t k_0__ = 0; k_0__ < v0_k_0_max__; ++k_0__) {
                v0[k_0__] = vals_i__[pos__++];
            }
            size_t v0_i_0_max__ = get_base1(num_non_zero, 1, "num_non_zero", 1);
            for (size_t i_0__ = 0; i_0__ < v0_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "v0[i_0__]", v0[i_0__], 0);
                check_less_or_equal(function__, "v0[i_0__]", v0[i_0__], (q - 1));
            }

            current_statement_begin__ = 636;
            validate_non_negative_index("v1", "get_base1(num_non_zero, 2, \"num_non_zero\", 1)", get_base1(num_non_zero, 2, "num_non_zero", 1));
            context__.validate_dims("data initialization", "v1", "int", context__.to_vec(get_base1(num_non_zero, 2, "num_non_zero", 1)));
            v1 = std::vector<int>(get_base1(num_non_zero, 2, "num_non_zero", 1), int(0));
            vals_i__ = context__.vals_i("v1");
            pos__ = 0;
            size_t v1_k_0_max__ = get_base1(num_non_zero, 2, "num_non_zero", 1);
            for (size_t k_0__ = 0; k_0__ < v1_k_0_max__; ++k_0__) {
                v1[k_0__] = vals_i__[pos__++];
            }
            size_t v1_i_0_max__ = get_base1(num_non_zero, 2, "num_non_zero", 1);
            for (size_t i_0__ = 0; i_0__ < v1_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "v1[i_0__]", v1[i_0__], 0);
                check_less_or_equal(function__, "v1[i_0__]", v1[i_0__], (q - 1));
            }

            current_statement_begin__ = 638;
            validate_non_negative_index("u0", "(logical_gt(t, 0) ? (get_base1(N, 1, \"N\", 1) + 1) : 0 )", (logical_gt(t, 0) ? (get_base1(N, 1, "N", 1) + 1) : 0 ));
            context__.validate_dims("data initialization", "u0", "int", context__.to_vec((logical_gt(t, 0) ? (get_base1(N, 1, "N", 1) + 1) : 0 )));
            u0 = std::vector<int>((logical_gt(t, 0) ? (get_base1(N, 1, "N", 1) + 1) : 0 ), int(0));
            vals_i__ = context__.vals_i("u0");
            pos__ = 0;
            size_t u0_k_0_max__ = (logical_gt(t, 0) ? (get_base1(N, 1, "N", 1) + 1) : 0 );
            for (size_t k_0__ = 0; k_0__ < u0_k_0_max__; ++k_0__) {
                u0[k_0__] = vals_i__[pos__++];
            }
            size_t u0_i_0_max__ = (logical_gt(t, 0) ? (get_base1(N, 1, "N", 1) + 1) : 0 );
            for (size_t i_0__ = 0; i_0__ < u0_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "u0[i_0__]", u0[i_0__], 0);
                check_less_or_equal(function__, "u0[i_0__]", u0[i_0__], (rows(w0) + 1));
            }

            current_statement_begin__ = 640;
            validate_non_negative_index("u1", "(logical_gt(t, 0) ? (get_base1(N, 2, \"N\", 1) + 1) : 0 )", (logical_gt(t, 0) ? (get_base1(N, 2, "N", 1) + 1) : 0 ));
            context__.validate_dims("data initialization", "u1", "int", context__.to_vec((logical_gt(t, 0) ? (get_base1(N, 2, "N", 1) + 1) : 0 )));
            u1 = std::vector<int>((logical_gt(t, 0) ? (get_base1(N, 2, "N", 1) + 1) : 0 ), int(0));
            vals_i__ = context__.vals_i("u1");
            pos__ = 0;
            size_t u1_k_0_max__ = (logical_gt(t, 0) ? (get_base1(N, 2, "N", 1) + 1) : 0 );
            for (size_t k_0__ = 0; k_0__ < u1_k_0_max__; ++k_0__) {
                u1[k_0__] = vals_i__[pos__++];
            }
            size_t u1_i_0_max__ = (logical_gt(t, 0) ? (get_base1(N, 2, "N", 1) + 1) : 0 );
            for (size_t i_0__ = 0; i_0__ < u1_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "u1[i_0__]", u1[i_0__], 0);
                check_less_or_equal(function__, "u1[i_0__]", u1[i_0__], (rows(w1) + 1));
            }

            current_statement_begin__ = 641;
            context__.validate_dims("data initialization", "special_case", "int", context__.to_vec());
            special_case = int(0);
            vals_i__ = context__.vals_i("special_case");
            pos__ = 0;
            special_case = vals_i__[pos__++];
            check_greater_or_equal(function__, "special_case", special_case, 0);
            check_less_or_equal(function__, "special_case", special_case, 1);


            // initialize transformed data variables
            current_statement_begin__ = 644;
            aux = double(0);
            stan::math::fill(aux, DUMMY_VAR__);
            stan::math::assign(aux,stan::math::not_a_number());

            current_statement_begin__ = 645;
            validate_non_negative_index("V0", "(special_case ? t : 0 )", (special_case ? t : 0 ));
            validate_non_negative_index("V0", "get_base1(N, 1, \"N\", 1)", get_base1(N, 1, "N", 1));
            V0 = std::vector<std::vector<int> >((special_case ? t : 0 ), std::vector<int>(get_base1(N, 1, "N", 1), int(0)));
            stan::math::fill(V0, std::numeric_limits<int>::min());
            stan::math::assign(V0,make_V(get_base1(N, 1, "N", 1), (special_case ? t : 0 ), v0, pstream__));

            current_statement_begin__ = 646;
            validate_non_negative_index("V1", "(special_case ? t : 0 )", (special_case ? t : 0 ));
            validate_non_negative_index("V1", "get_base1(N, 2, \"N\", 1)", get_base1(N, 2, "N", 1));
            V1 = std::vector<std::vector<int> >((special_case ? t : 0 ), std::vector<int>(get_base1(N, 2, "N", 1), int(0)));
            stan::math::fill(V1, std::numeric_limits<int>::min());
            stan::math::assign(V1,make_V(get_base1(N, 2, "N", 1), (special_case ? t : 0 ), v1, pstream__));

            current_statement_begin__ = 648;
            len_z_T = int(0);
            stan::math::fill(len_z_T, std::numeric_limits<int>::min());
            stan::math::assign(len_z_T,0);

            current_statement_begin__ = 649;
            len_var_group = int(0);
            stan::math::fill(len_var_group, std::numeric_limits<int>::min());
            stan::math::assign(len_var_group,(sum(p) * logical_gt(t, 0)));

            current_statement_begin__ = 650;
            len_rho = int(0);
            stan::math::fill(len_rho, std::numeric_limits<int>::min());
            stan::math::assign(len_rho,(sum(p) - t));

            current_statement_begin__ = 651;
            is_continuous = int(0);
            stan::math::fill(is_continuous, std::numeric_limits<int>::min());
            stan::math::assign(is_continuous,0);

            current_statement_begin__ = 652;
            pos = int(0);
            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);

            current_statement_begin__ = 653;
            validate_non_negative_index("del", "len_concentration", len_concentration);
            del = std::vector<double>(len_concentration, double(0));
            stan::math::fill(del, DUMMY_VAR__);

            current_statement_begin__ = 654;
            hs = int(0);
            stan::math::fill(hs, std::numeric_limits<int>::min());

            // execute transformed data statements
            current_statement_begin__ = 655;
            if (as_bool(logical_lte(prior_dist, 2))) {
                current_statement_begin__ = 655;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist, 3))) {
                current_statement_begin__ = 656;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist, 4))) {
                current_statement_begin__ = 657;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 658;
                stan::math::assign(hs, 0);
            }
            current_statement_begin__ = 660;
            stan::math::assign(pos, 1);
            current_statement_begin__ = 661;
            for (int i = 1; i <= t; ++i) {

                current_statement_begin__ = 662;
                if (as_bool(logical_gt(get_base1(p, i, "p", 1), 1))) {

                    current_statement_begin__ = 663;
                    for (int j = 1; j <= get_base1(p, i, "p", 1); ++j) {

                        current_statement_begin__ = 664;
                        stan::model::assign(del, 
                                    stan::model::cons_list(stan::model::index_uni(pos), stan::model::nil_index_list()), 
                                    get_base1(concentration, j, "concentration", 1), 
                                    "assigning variable del");
                        current_statement_begin__ = 665;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
                current_statement_begin__ = 668;
                for (int j = 3; j <= get_base1(p, i, "p", 1); ++j) {
                    current_statement_begin__ = 668;
                    stan::math::assign(len_z_T, ((len_z_T + get_base1(p, i, "p", 1)) - 1));
                }
            }

            // validate transformed data
            current_statement_begin__ = 645;
            size_t V0_i_0_max__ = (special_case ? t : 0 );
            size_t V0_i_1_max__ = get_base1(N, 1, "N", 1);
            for (size_t i_0__ = 0; i_0__ < V0_i_0_max__; ++i_0__) {
                for (size_t i_1__ = 0; i_1__ < V0_i_1_max__; ++i_1__) {
                    check_greater_or_equal(function__, "V0[i_0__][i_1__]", V0[i_0__][i_1__], 1);
                }
            }

            current_statement_begin__ = 646;
            size_t V1_i_0_max__ = (special_case ? t : 0 );
            size_t V1_i_1_max__ = get_base1(N, 2, "N", 1);
            for (size_t i_0__ = 0; i_0__ < V1_i_0_max__; ++i_0__) {
                for (size_t i_1__ = 0; i_1__ < V1_i_1_max__; ++i_1__) {
                    check_greater_or_equal(function__, "V1[i_0__][i_1__]", V1[i_0__][i_1__], 1);
                }
            }

            current_statement_begin__ = 648;
            check_greater_or_equal(function__, "len_z_T", len_z_T, 0);

            current_statement_begin__ = 649;
            check_greater_or_equal(function__, "len_var_group", len_var_group, 0);

            current_statement_begin__ = 650;
            check_greater_or_equal(function__, "len_rho", len_rho, 0);

            current_statement_begin__ = 651;
            check_greater_or_equal(function__, "is_continuous", is_continuous, 0);
            check_less_or_equal(function__, "is_continuous", is_continuous, 1);

            current_statement_begin__ = 652;
            check_greater_or_equal(function__, "pos", pos, 1);

            current_statement_begin__ = 653;
            size_t del_i_0_max__ = len_concentration;
            for (size_t i_0__ = 0; i_0__ < del_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "del[i_0__]", del[i_0__], 0);
            }

            current_statement_begin__ = 654;
            check_greater_or_equal(function__, "hs", hs, 0);


            // validate, set parameter ranges
            num_params_r__ = 0U;
            param_ranges_i__.clear();
            current_statement_begin__ = 672;
            validate_non_negative_index("gamma", "has_intercept", has_intercept);
            num_params_r__ += (1 * has_intercept);
            current_statement_begin__ = 674;
            validate_non_negative_index("z_delta", "(logical_eq(prior_dist, 7) ? sum(num_normals) : K )", (logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
            num_params_r__ += (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
            current_statement_begin__ = 675;
            validate_non_negative_index("mix", "K", K);
            validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)))", (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
            num_params_r__ += (K * (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
            current_statement_begin__ = 676;
            validate_non_negative_index("z_beta", "(logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q )", (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ));
            num_params_r__ += (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q );
            current_statement_begin__ = 677;
            validate_non_negative_index("mix_stap", "Q", Q);
            validate_non_negative_index("mix_stap", "(primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)))", (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6))));
            num_params_r__ += (Q * (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6))));
            current_statement_begin__ = 678;
            validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist, 6)", logical_eq(prior_dist, 6));
            num_params_r__ += (1 * logical_eq(prior_dist, 6));
            current_statement_begin__ = 679;
            validate_non_negative_index("one_over_lambda_stap", "logical_eq(prior_dist_for_stap, 6)", logical_eq(prior_dist_for_stap, 6));
            num_params_r__ += (1 * logical_eq(prior_dist_for_stap, 6));
            current_statement_begin__ = 680;
            validate_non_negative_index("theta_s", "(Q_s + Q_st)", (Q_s + Q_st));
            num_params_r__ += (1 * (Q_s + Q_st));
            current_statement_begin__ = 681;
            validate_non_negative_index("shape_s", "num_s_wei", num_s_wei);
            num_params_r__ += (1 * num_s_wei);
            current_statement_begin__ = 682;
            validate_non_negative_index("shape_t", "num_t_wei", num_t_wei);
            num_params_r__ += (1 * num_t_wei);
            current_statement_begin__ = 683;
            validate_non_negative_index("theta_t", "(Q_t + Q_st)", (Q_t + Q_st));
            num_params_r__ += (1 * (Q_t + Q_st));
            current_statement_begin__ = 684;
            validate_non_negative_index("z_b", "q", q);
            num_params_r__ += q;
            current_statement_begin__ = 685;
            validate_non_negative_index("z_T", "len_z_T", len_z_T);
            num_params_r__ += len_z_T;
            current_statement_begin__ = 686;
            validate_non_negative_index("rho", "len_rho", len_rho);
            num_params_r__ += len_rho;
            current_statement_begin__ = 687;
            validate_non_negative_index("zeta", "len_concentration", len_concentration);
            num_params_r__ += len_concentration;
            current_statement_begin__ = 688;
            validate_non_negative_index("tau", "t", t);
            num_params_r__ += t;
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }

    ~model_stap_bernoulli() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        typedef double local_scalar_t__;
        stan::io::writer<double> writer__(params_r__, params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        current_statement_begin__ = 672;
        if (!(context__.contains_r("gamma")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable gamma missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("parameter initialization", "gamma", "double", context__.to_vec(has_intercept));
        std::vector<double> gamma(has_intercept, double(0));
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            gamma[k_0__] = vals_r__[pos__++];
        }
        size_t gamma_i_0_max__ = has_intercept;
        for (size_t i_0__ = 0; i_0__ < gamma_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_ub_unconstrain((logical_eq(link, 4) ? 0.0 : stan::math::positive_infinity() ), gamma[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable gamma: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 674;
        if (!(context__.contains_r("z_delta")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_delta missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_delta");
        pos__ = 0U;
        validate_non_negative_index("z_delta", "(logical_eq(prior_dist, 7) ? sum(num_normals) : K )", (logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        context__.validate_dims("parameter initialization", "z_delta", "vector_d", context__.to_vec((logical_eq(prior_dist, 7) ? sum(num_normals) : K )));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_delta((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        size_t z_delta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_delta_j_1_max__; ++j_1__) {
            z_delta(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_delta);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_delta: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 675;
        if (!(context__.contains_r("mix")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable mix missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)))", (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
        context__.validate_dims("parameter initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))),K));
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mix((primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))), Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                mix[k_0__](j_1__) = vals_r__[pos__++];
            }
        }
        size_t mix_i_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t i_0__ = 0; i_0__ < mix_i_0_max__; ++i_0__) {
            try {
                writer__.vector_lb_unconstrain(0, mix[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable mix: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 676;
        if (!(context__.contains_r("z_beta")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_beta missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q )", (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ));
        context__.validate_dims("parameter initialization", "z_beta", "vector_d", context__.to_vec((logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q )));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_beta((logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ));
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            z_beta(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 677;
        if (!(context__.contains_r("mix_stap")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable mix_stap missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("mix_stap");
        pos__ = 0U;
        validate_non_negative_index("mix_stap", "Q", Q);
        validate_non_negative_index("mix_stap", "(primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)))", (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6))));
        context__.validate_dims("parameter initialization", "mix_stap", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6))),Q));
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mix_stap((primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6))), Eigen::Matrix<double, Eigen::Dynamic, 1>(Q));
        size_t mix_stap_j_1_max__ = Q;
        size_t mix_stap_k_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_stap_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_stap_k_0_max__; ++k_0__) {
                mix_stap[k_0__](j_1__) = vals_r__[pos__++];
            }
        }
        size_t mix_stap_i_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
        for (size_t i_0__ = 0; i_0__ < mix_stap_i_0_max__; ++i_0__) {
            try {
                writer__.vector_lb_unconstrain(0, mix_stap[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable mix_stap: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 678;
        if (!(context__.contains_r("one_over_lambda")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable one_over_lambda missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist, 6)", logical_eq(prior_dist, 6));
        context__.validate_dims("parameter initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist, 6)));
        std::vector<double> one_over_lambda(logical_eq(prior_dist, 6), double(0));
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            one_over_lambda[k_0__] = vals_r__[pos__++];
        }
        size_t one_over_lambda_i_0_max__ = logical_eq(prior_dist, 6);
        for (size_t i_0__ = 0; i_0__ < one_over_lambda_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, one_over_lambda[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 679;
        if (!(context__.contains_r("one_over_lambda_stap")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable one_over_lambda_stap missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("one_over_lambda_stap");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda_stap", "logical_eq(prior_dist_for_stap, 6)", logical_eq(prior_dist_for_stap, 6));
        context__.validate_dims("parameter initialization", "one_over_lambda_stap", "double", context__.to_vec(logical_eq(prior_dist_for_stap, 6)));
        std::vector<double> one_over_lambda_stap(logical_eq(prior_dist_for_stap, 6), double(0));
        size_t one_over_lambda_stap_k_0_max__ = logical_eq(prior_dist_for_stap, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_stap_k_0_max__; ++k_0__) {
            one_over_lambda_stap[k_0__] = vals_r__[pos__++];
        }
        size_t one_over_lambda_stap_i_0_max__ = logical_eq(prior_dist_for_stap, 6);
        for (size_t i_0__ = 0; i_0__ < one_over_lambda_stap_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, one_over_lambda_stap[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable one_over_lambda_stap: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 680;
        if (!(context__.contains_r("theta_s")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable theta_s missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("theta_s");
        pos__ = 0U;
        validate_non_negative_index("theta_s", "(Q_s + Q_st)", (Q_s + Q_st));
        context__.validate_dims("parameter initialization", "theta_s", "double", context__.to_vec((Q_s + Q_st)));
        std::vector<double> theta_s((Q_s + Q_st), double(0));
        size_t theta_s_k_0_max__ = (Q_s + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_s_k_0_max__; ++k_0__) {
            theta_s[k_0__] = vals_r__[pos__++];
        }
        size_t theta_s_i_0_max__ = (Q_s + Q_st);
        for (size_t i_0__ = 0; i_0__ < theta_s_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lub_unconstrain(0, max_distance, theta_s[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable theta_s: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 681;
        if (!(context__.contains_r("shape_s")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable shape_s missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("shape_s");
        pos__ = 0U;
        validate_non_negative_index("shape_s", "num_s_wei", num_s_wei);
        context__.validate_dims("parameter initialization", "shape_s", "double", context__.to_vec(num_s_wei));
        std::vector<double> shape_s(num_s_wei, double(0));
        size_t shape_s_k_0_max__ = num_s_wei;
        for (size_t k_0__ = 0; k_0__ < shape_s_k_0_max__; ++k_0__) {
            shape_s[k_0__] = vals_r__[pos__++];
        }
        size_t shape_s_i_0_max__ = num_s_wei;
        for (size_t i_0__ = 0; i_0__ < shape_s_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, shape_s[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable shape_s: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 682;
        if (!(context__.contains_r("shape_t")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable shape_t missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("shape_t");
        pos__ = 0U;
        validate_non_negative_index("shape_t", "num_t_wei", num_t_wei);
        context__.validate_dims("parameter initialization", "shape_t", "double", context__.to_vec(num_t_wei));
        std::vector<double> shape_t(num_t_wei, double(0));
        size_t shape_t_k_0_max__ = num_t_wei;
        for (size_t k_0__ = 0; k_0__ < shape_t_k_0_max__; ++k_0__) {
            shape_t[k_0__] = vals_r__[pos__++];
        }
        size_t shape_t_i_0_max__ = num_t_wei;
        for (size_t i_0__ = 0; i_0__ < shape_t_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, shape_t[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable shape_t: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 683;
        if (!(context__.contains_r("theta_t")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable theta_t missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("theta_t");
        pos__ = 0U;
        validate_non_negative_index("theta_t", "(Q_t + Q_st)", (Q_t + Q_st));
        context__.validate_dims("parameter initialization", "theta_t", "double", context__.to_vec((Q_t + Q_st)));
        std::vector<double> theta_t((Q_t + Q_st), double(0));
        size_t theta_t_k_0_max__ = (Q_t + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_t_k_0_max__; ++k_0__) {
            theta_t[k_0__] = vals_r__[pos__++];
        }
        size_t theta_t_i_0_max__ = (Q_t + Q_st);
        for (size_t i_0__ = 0; i_0__ < theta_t_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lub_unconstrain(0, max_time, theta_t[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable theta_t: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 684;
        if (!(context__.contains_r("z_b")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_b missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_b");
        pos__ = 0U;
        validate_non_negative_index("z_b", "q", q);
        context__.validate_dims("parameter initialization", "z_b", "vector_d", context__.to_vec(q));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_b(q);
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            z_b(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_b);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_b: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 685;
        if (!(context__.contains_r("z_T")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_T missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_T");
        pos__ = 0U;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        context__.validate_dims("parameter initialization", "z_T", "vector_d", context__.to_vec(len_z_T));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_T(len_z_T);
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            z_T(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_T);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_T: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 686;
        if (!(context__.contains_r("rho")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable rho missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "len_rho", len_rho);
        context__.validate_dims("parameter initialization", "rho", "vector_d", context__.to_vec(len_rho));
        Eigen::Matrix<double, Eigen::Dynamic, 1> rho(len_rho);
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            rho(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lub_unconstrain(0, 1, rho);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable rho: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 687;
        if (!(context__.contains_r("zeta")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable zeta missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("zeta");
        pos__ = 0U;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        context__.validate_dims("parameter initialization", "zeta", "vector_d", context__.to_vec(len_concentration));
        Eigen::Matrix<double, Eigen::Dynamic, 1> zeta(len_concentration);
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            zeta(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lb_unconstrain(0, zeta);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable zeta: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 688;
        if (!(context__.contains_r("tau")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable tau missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "t", t);
        context__.validate_dims("parameter initialization", "tau", "vector_d", context__.to_vec(t));
        Eigen::Matrix<double, Eigen::Dynamic, 1> tau(t);
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            tau(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lb_unconstrain(0, tau);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable tau: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double, Eigen::Dynamic, 1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(std::vector<T__>& params_r__,
                 std::vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        typedef T__ local_scalar_t__;

        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // dummy to suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;
        try {
            stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);

            // model parameters
            current_statement_begin__ = 672;
            std::vector<local_scalar_t__> gamma;
            size_t gamma_d_0_max__ = has_intercept;
            gamma.reserve(gamma_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < gamma_d_0_max__; ++d_0__) {
                if (jacobian__)
                    gamma.push_back(in__.scalar_ub_constrain((logical_eq(link, 4) ? 0.0 : stan::math::positive_infinity() ), lp__));
                else
                    gamma.push_back(in__.scalar_ub_constrain((logical_eq(link, 4) ? 0.0 : stan::math::positive_infinity() )));
            }

            current_statement_begin__ = 674;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_delta;
            (void) z_delta;  // dummy to suppress unused var warning
            if (jacobian__)
                z_delta = in__.vector_constrain((logical_eq(prior_dist, 7) ? sum(num_normals) : K ), lp__);
            else
                z_delta = in__.vector_constrain((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));

            current_statement_begin__ = 675;
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > mix;
            size_t mix_d_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
            mix.reserve(mix_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < mix_d_0_max__; ++d_0__) {
                if (jacobian__)
                    mix.push_back(in__.vector_lb_constrain(0, K, lp__));
                else
                    mix.push_back(in__.vector_lb_constrain(0, K));
            }

            current_statement_begin__ = 676;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_beta;
            (void) z_beta;  // dummy to suppress unused var warning
            if (jacobian__)
                z_beta = in__.vector_constrain((logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ), lp__);
            else
                z_beta = in__.vector_constrain((logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ));

            current_statement_begin__ = 677;
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > mix_stap;
            size_t mix_stap_d_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
            mix_stap.reserve(mix_stap_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < mix_stap_d_0_max__; ++d_0__) {
                if (jacobian__)
                    mix_stap.push_back(in__.vector_lb_constrain(0, Q, lp__));
                else
                    mix_stap.push_back(in__.vector_lb_constrain(0, Q));
            }

            current_statement_begin__ = 678;
            std::vector<local_scalar_t__> one_over_lambda;
            size_t one_over_lambda_d_0_max__ = logical_eq(prior_dist, 6);
            one_over_lambda.reserve(one_over_lambda_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < one_over_lambda_d_0_max__; ++d_0__) {
                if (jacobian__)
                    one_over_lambda.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    one_over_lambda.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 679;
            std::vector<local_scalar_t__> one_over_lambda_stap;
            size_t one_over_lambda_stap_d_0_max__ = logical_eq(prior_dist_for_stap, 6);
            one_over_lambda_stap.reserve(one_over_lambda_stap_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < one_over_lambda_stap_d_0_max__; ++d_0__) {
                if (jacobian__)
                    one_over_lambda_stap.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    one_over_lambda_stap.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 680;
            std::vector<local_scalar_t__> theta_s;
            size_t theta_s_d_0_max__ = (Q_s + Q_st);
            theta_s.reserve(theta_s_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < theta_s_d_0_max__; ++d_0__) {
                if (jacobian__)
                    theta_s.push_back(in__.scalar_lub_constrain(0, max_distance, lp__));
                else
                    theta_s.push_back(in__.scalar_lub_constrain(0, max_distance));
            }

            current_statement_begin__ = 681;
            std::vector<local_scalar_t__> shape_s;
            size_t shape_s_d_0_max__ = num_s_wei;
            shape_s.reserve(shape_s_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < shape_s_d_0_max__; ++d_0__) {
                if (jacobian__)
                    shape_s.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    shape_s.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 682;
            std::vector<local_scalar_t__> shape_t;
            size_t shape_t_d_0_max__ = num_t_wei;
            shape_t.reserve(shape_t_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < shape_t_d_0_max__; ++d_0__) {
                if (jacobian__)
                    shape_t.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    shape_t.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 683;
            std::vector<local_scalar_t__> theta_t;
            size_t theta_t_d_0_max__ = (Q_t + Q_st);
            theta_t.reserve(theta_t_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < theta_t_d_0_max__; ++d_0__) {
                if (jacobian__)
                    theta_t.push_back(in__.scalar_lub_constrain(0, max_time, lp__));
                else
                    theta_t.push_back(in__.scalar_lub_constrain(0, max_time));
            }

            current_statement_begin__ = 684;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_b;
            (void) z_b;  // dummy to suppress unused var warning
            if (jacobian__)
                z_b = in__.vector_constrain(q, lp__);
            else
                z_b = in__.vector_constrain(q);

            current_statement_begin__ = 685;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_T;
            (void) z_T;  // dummy to suppress unused var warning
            if (jacobian__)
                z_T = in__.vector_constrain(len_z_T, lp__);
            else
                z_T = in__.vector_constrain(len_z_T);

            current_statement_begin__ = 686;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> rho;
            (void) rho;  // dummy to suppress unused var warning
            if (jacobian__)
                rho = in__.vector_lub_constrain(0, 1, len_rho, lp__);
            else
                rho = in__.vector_lub_constrain(0, 1, len_rho);

            current_statement_begin__ = 687;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> zeta;
            (void) zeta;  // dummy to suppress unused var warning
            if (jacobian__)
                zeta = in__.vector_lb_constrain(0, len_concentration, lp__);
            else
                zeta = in__.vector_lb_constrain(0, len_concentration);

            current_statement_begin__ = 688;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> tau;
            (void) tau;  // dummy to suppress unused var warning
            if (jacobian__)
                tau = in__.vector_lb_constrain(0, t, lp__);
            else
                tau = in__.vector_lb_constrain(0, t);

            // transformed parameters
            current_statement_begin__ = 692;
            validate_non_negative_index("delta", "K", K);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> delta(K);
            stan::math::initialize(delta, DUMMY_VAR__);
            stan::math::fill(delta, DUMMY_VAR__);

            current_statement_begin__ = 693;
            validate_non_negative_index("beta", "Q", Q);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> beta(Q);
            stan::math::initialize(beta, DUMMY_VAR__);
            stan::math::fill(beta, DUMMY_VAR__);

            current_statement_begin__ = 694;
            validate_non_negative_index("X", "NN", NN);
            validate_non_negative_index("X", "Q", Q);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> X(NN, Q);
            stan::math::initialize(X, DUMMY_VAR__);
            stan::math::fill(X, DUMMY_VAR__);

            current_statement_begin__ = 695;
            validate_non_negative_index("X_tilde", "NN", NN);
            validate_non_negative_index("X_tilde", "Q", Q);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> X_tilde(NN, Q);
            stan::math::initialize(X_tilde, DUMMY_VAR__);
            stan::math::fill(X_tilde, DUMMY_VAR__);

            current_statement_begin__ = 696;
            validate_non_negative_index("b", "q", q);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> b(q);
            stan::math::initialize(b, DUMMY_VAR__);
            stan::math::fill(b, DUMMY_VAR__);

            current_statement_begin__ = 697;
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> theta_L(len_theta_L);
            stan::math::initialize(theta_L, DUMMY_VAR__);
            stan::math::fill(theta_L, DUMMY_VAR__);

            // transformed parameters block statements
            {
            current_statement_begin__ = 701;
            int cnt_s(0);
            (void) cnt_s;  // dummy to suppress unused var warning
            stan::math::fill(cnt_s, std::numeric_limits<int>::min());
            stan::math::assign(cnt_s,1);

            current_statement_begin__ = 702;
            int cnt_t(0);
            (void) cnt_t;  // dummy to suppress unused var warning
            stan::math::fill(cnt_t, std::numeric_limits<int>::min());
            stan::math::assign(cnt_t,1);

            current_statement_begin__ = 703;
            int cnt_shape_s(0);
            (void) cnt_shape_s;  // dummy to suppress unused var warning
            stan::math::fill(cnt_shape_s, std::numeric_limits<int>::min());
            stan::math::assign(cnt_shape_s,1);

            current_statement_begin__ = 704;
            int cnt_shape_t(0);
            (void) cnt_shape_t;  // dummy to suppress unused var warning
            stan::math::fill(cnt_shape_t, std::numeric_limits<int>::min());
            stan::math::assign(cnt_shape_t,1);


            current_statement_begin__ = 705;
            for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                current_statement_begin__ = 706;
                for (int n = 1; n <= NN; ++n) {

                    current_statement_begin__ = 707;
                    if (as_bool(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 0))) {
                        current_statement_begin__ = 708;
                        stan::model::assign(X, 
                                    stan::model::cons_list(stan::model::index_uni(n), stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list())), 
                                    assign_exposure(get_base1(log_ar, q_ix, "log_ar", 1), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), u_s, get_base1(dists_crs, cnt_s, "dists_crs", 1), get_base1(theta_s, cnt_s, "theta_s", 1), shape_s, cnt_shape_s, q_ix, n, pstream__), 
                                    "assigning variable X");
                    } else if (as_bool(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 1))) {
                        current_statement_begin__ = 710;
                        stan::model::assign(X, 
                                    stan::model::cons_list(stan::model::index_uni(n), stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list())), 
                                    assign_exposure(get_base1(log_ar, q_ix, "log_ar", 1), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), u_t, get_base1(times_crs, cnt_t, "times_crs", 1), get_base1(theta_t, cnt_t, "theta_t", 1), shape_t, cnt_shape_t, q_ix, n, pstream__), 
                                    "assigning variable X");
                    } else {
                        current_statement_begin__ = 712;
                        stan::model::assign(X, 
                                    stan::model::cons_list(stan::model::index_uni(n), stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list())), 
                                    assign_st_exposure(get_base1(log_ar, q_ix, "log_ar", 1), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), u_s, u_t, get_base1(dists_crs, cnt_s, "dists_crs", 1), get_base1(times_crs, cnt_t, "times_crs", 1), get_base1(theta_s, cnt_s, "theta_s", 1), get_base1(theta_t, cnt_t, "theta_t", 1), shape_s, shape_t, cnt_shape_s, cnt_shape_t, q_ix, n, pstream__), 
                                    "assigning variable X");
                    }
                }
                current_statement_begin__ = 714;
                if (as_bool((primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 0)) || primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 2))))) {

                    current_statement_begin__ = 715;
                    stan::math::assign(cnt_s, (cnt_s + 1));
                    current_statement_begin__ = 716;
                    stan::math::assign(cnt_shape_s, (cnt_shape_s + (logical_eq(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), 5) ? 1 : 0 )));
                }
                current_statement_begin__ = 718;
                if (as_bool((primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 1)) || primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 2))))) {

                    current_statement_begin__ = 719;
                    stan::math::assign(cnt_t, (cnt_t + 1));
                    current_statement_begin__ = 720;
                    stan::math::assign(cnt_shape_t, (cnt_shape_t + (logical_eq(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), 6) ? 1 : 0 )));
                }
            }
            }
            current_statement_begin__ = 725;
            stan::math::assign(X_tilde, centerscale(X, pstream__));
            current_statement_begin__ = 728;
            if (as_bool(logical_eq(prior_dist, 0))) {
                current_statement_begin__ = 728;
                stan::math::assign(delta, z_delta);
            } else if (as_bool(logical_eq(prior_dist, 1))) {
                current_statement_begin__ = 729;
                stan::math::assign(delta, add(elt_multiply(z_delta, prior_scale), prior_mean));
            } else if (as_bool(logical_eq(prior_dist, 2))) {

                current_statement_begin__ = 731;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 732;
                    stan::model::assign(delta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                ((CFt(get_base1(z_delta, k, "z_delta", 1), get_base1(prior_df, k, "prior_df", 1), pstream__) * get_base1(prior_scale, k, "prior_scale", 1)) + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable delta");
                }
            } else if (as_bool(logical_eq(prior_dist, 5))) {
                current_statement_begin__ = 736;
                stan::math::assign(delta, add(prior_mean, elt_multiply(elt_multiply(prior_scale, stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_delta)));
            } else if (as_bool(logical_eq(prior_dist, 6))) {
                current_statement_begin__ = 738;
                stan::math::assign(delta, add(prior_mean, elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda, 1, "one_over_lambda", 1), prior_scale), stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_delta)));
            } else if (as_bool(logical_eq(prior_dist, 7))) {
                {
                current_statement_begin__ = 740;
                int z_pos(0);
                (void) z_pos;  // dummy to suppress unused var warning
                stan::math::fill(z_pos, std::numeric_limits<int>::min());
                stan::math::assign(z_pos,1);


                current_statement_begin__ = 741;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 742;
                    stan::model::assign(delta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                get_base1(z_delta, z_pos, "z_delta", 1), 
                                "assigning variable delta");
                    current_statement_begin__ = 743;
                    stan::math::assign(z_pos, (z_pos + 1));
                    current_statement_begin__ = 744;
                    for (int n = 2; n <= get_base1(num_normals, k, "num_normals", 1); ++n) {

                        current_statement_begin__ = 745;
                        stan::model::assign(delta, 
                                    stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                    (get_base1(delta, k, "delta", 1) * get_base1(z_delta, z_pos, "z_delta", 1)), 
                                    "assigning variable delta");
                        current_statement_begin__ = 746;
                        stan::math::assign(z_pos, (z_pos + 1));
                    }
                    current_statement_begin__ = 748;
                    stan::model::assign(delta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                ((get_base1(delta, k, "delta", 1) * pow(get_base1(prior_scale, k, "prior_scale", 1), get_base1(num_normals, k, "num_normals", 1))) + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable delta");
                }
                }
            }
            current_statement_begin__ = 753;
            if (as_bool(logical_eq(prior_dist_for_stap, 0))) {
                current_statement_begin__ = 753;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist_for_stap, 1))) {
                current_statement_begin__ = 754;
                stan::math::assign(beta, add(elt_multiply(z_beta, prior_scale_for_stap), prior_mean_for_stap));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 2))) {
                current_statement_begin__ = 755;
                for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                    current_statement_begin__ = 756;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                ((CFt(get_base1(z_beta, q_ix, "z_beta", 1), get_base1(prior_df_for_stap, q_ix, "prior_df_for_stap", 1), pstream__) * get_base1(prior_scale_for_stap, q_ix, "prior_scale_for_stap", 1)) + get_base1(prior_mean_for_stap, q_ix, "prior_mean_for_stap", 1)), 
                                "assigning variable beta");
                }
            } else if (as_bool(logical_eq(prior_dist_for_stap, 5))) {
                current_statement_begin__ = 759;
                stan::math::assign(beta, add(prior_mean_for_stap, elt_multiply(elt_multiply(prior_scale_for_stap, stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 6))) {
                current_statement_begin__ = 761;
                stan::math::assign(beta, add(prior_mean_for_stap, elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda, 1, "one_over_lambda", 1), prior_scale_for_stap), stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 7))) {
                {
                current_statement_begin__ = 763;
                int z_pos(0);
                (void) z_pos;  // dummy to suppress unused var warning
                stan::math::fill(z_pos, std::numeric_limits<int>::min());
                stan::math::assign(z_pos,1);


                current_statement_begin__ = 764;
                for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                    current_statement_begin__ = 765;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                get_base1(z_beta, z_pos, "z_beta", 1), 
                                "assigning variable beta");
                    current_statement_begin__ = 766;
                    stan::math::assign(z_pos, (z_pos + 1));
                    current_statement_begin__ = 767;
                    for (int n = 2; n <= get_base1(num_normals_for_stap, q_ix, "num_normals_for_stap", 1); ++n) {

                        current_statement_begin__ = 768;
                        stan::model::assign(beta, 
                                    stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                    (get_base1(beta, q_ix, "beta", 1) * get_base1(z_delta, z_pos, "z_delta", 1)), 
                                    "assigning variable beta");
                        current_statement_begin__ = 769;
                        stan::math::assign(z_pos, (z_pos + 1));
                    }
                    current_statement_begin__ = 771;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                ((get_base1(delta, q_ix, "delta", 1) * pow(get_base1(prior_scale_for_stap, q_ix, "prior_scale_for_stap", 1), get_base1(num_normals_for_stap, q_ix, "num_normals_for_stap", 1))) + get_base1(prior_mean_for_stap, q_ix, "prior_mean_for_stap", 1)), 
                                "assigning variable beta");
                }
                }
            }
            current_statement_begin__ = 774;
            if (as_bool(logical_gt(t, 0))) {

                current_statement_begin__ = 775;
                if (as_bool(special_case)) {
                    {
                    current_statement_begin__ = 776;
                    int start(0);
                    (void) start;  // dummy to suppress unused var warning
                    stan::math::fill(start, std::numeric_limits<int>::min());
                    stan::math::assign(start,1);


                    current_statement_begin__ = 777;
                    stan::math::assign(theta_L, elt_multiply(scale, tau));
                    current_statement_begin__ = 778;
                    if (as_bool(logical_eq(t, 1))) {
                        current_statement_begin__ = 778;
                        stan::math::assign(b, multiply(get_base1(theta_L, 1, "theta_L", 1), z_b));
                    } else {
                        current_statement_begin__ = 779;
                        for (int i = 1; i <= t; ++i) {
                            {
                            current_statement_begin__ = 780;
                            int end(0);
                            (void) end;  // dummy to suppress unused var warning
                            stan::math::fill(end, std::numeric_limits<int>::min());
                            stan::math::assign(end,((start + get_base1(l, i, "l", 1)) - 1));


                            current_statement_begin__ = 781;
                            stan::model::assign(b, 
                                        stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                        multiply(get_base1(theta_L, i, "theta_L", 1), stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                        "assigning variable b");
                            current_statement_begin__ = 782;
                            stan::math::assign(start, (end + 1));
                            }
                        }
                    }
                    }
                } else {

                    current_statement_begin__ = 786;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L, p, 1.0, tau, scale, zeta, rho, z_T, pstream__));
                    current_statement_begin__ = 788;
                    stan::math::assign(b, make_b(z_b, theta_L, p, l, pstream__));
                }
            }

            // validate transformed parameters
            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning

            current_statement_begin__ = 692;
            size_t delta_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < delta_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(delta(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: delta" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable delta: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }
            current_statement_begin__ = 693;
            size_t beta_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(beta(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: beta" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable beta: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }
            current_statement_begin__ = 694;
            size_t X_j_1_max__ = NN;
            size_t X_j_2_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                for (size_t j_2__ = 0; j_2__ < X_j_2_max__; ++j_2__) {
                    if (stan::math::is_uninitialized(X(j_1__, j_2__))) {
                        std::stringstream msg__;
                        msg__ << "Undefined transformed parameter: X" << "(" << j_1__ << ", " << j_2__ << ")";
                        stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable X: ") + msg__.str()), current_statement_begin__, prog_reader__());
                    }
                }
            }
            current_statement_begin__ = 695;
            size_t X_tilde_j_1_max__ = NN;
            size_t X_tilde_j_2_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < X_tilde_j_1_max__; ++j_1__) {
                for (size_t j_2__ = 0; j_2__ < X_tilde_j_2_max__; ++j_2__) {
                    if (stan::math::is_uninitialized(X_tilde(j_1__, j_2__))) {
                        std::stringstream msg__;
                        msg__ << "Undefined transformed parameter: X_tilde" << "(" << j_1__ << ", " << j_2__ << ")";
                        stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable X_tilde: ") + msg__.str()), current_statement_begin__, prog_reader__());
                    }
                }
            }
            current_statement_begin__ = 696;
            size_t b_j_1_max__ = q;
            for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(b(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: b" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable b: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }
            current_statement_begin__ = 697;
            size_t theta_L_j_1_max__ = len_theta_L;
            for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(theta_L(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: theta_L" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable theta_L: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }

            // model body
            {
            current_statement_begin__ = 795;
            validate_non_negative_index("eta0", "get_base1(N, 1, \"N\", 1)", get_base1(N, 1, "N", 1));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta0(get_base1(N, 1, "N", 1));
            stan::math::initialize(eta0, DUMMY_VAR__);
            stan::math::fill(eta0, DUMMY_VAR__);

            current_statement_begin__ = 796;
            validate_non_negative_index("eta1", "get_base1(N, 2, \"N\", 1)", get_base1(N, 2, "N", 1));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta1(get_base1(N, 2, "N", 1));
            stan::math::initialize(eta1, DUMMY_VAR__);
            stan::math::fill(eta1, DUMMY_VAR__);


            current_statement_begin__ = 797;
            stan::math::assign(eta0, rep_vector(0.0, get_base1(N, 1, "N", 1)));
            current_statement_begin__ = 798;
            stan::math::assign(eta1, rep_vector(0.0, get_base1(N, 2, "N", 1)));
            current_statement_begin__ = 800;
            if (as_bool(logical_eq(has_intercept, 0))) {
                {
                current_statement_begin__ = 801;
                local_scalar_t__ tmp(DUMMY_VAR__);
                (void) tmp;  // dummy to suppress unused var warning
                stan::math::initialize(tmp, DUMMY_VAR__);
                stan::math::fill(tmp, DUMMY_VAR__);


                current_statement_begin__ = 802;
                stan::math::assign(tmp, dot_product(zbar, delta));
                current_statement_begin__ = 803;
                stan::math::assign(eta0, add(eta0, tmp));
                current_statement_begin__ = 804;
                stan::math::assign(eta1, add(eta1, tmp));
                }
            } else {

                current_statement_begin__ = 806;
                stan::math::assign(eta0, add(add(eta0, multiply(Z0, delta)), multiply(stan::model::rvalue(X_tilde, stan::model::cons_list(stan::model::index_multi(y_0), stan::model::cons_list(stan::model::index_omni(), stan::model::nil_index_list())), "X_tilde"), beta)));
                current_statement_begin__ = 807;
                stan::math::assign(eta1, add(add(eta1, multiply(Z1, delta)), multiply(stan::model::rvalue(X_tilde, stan::model::cons_list(stan::model::index_multi(y_1), stan::model::cons_list(stan::model::index_omni(), stan::model::nil_index_list())), "X_tilde"), beta)));
            }
            current_statement_begin__ = 809;
            if (as_bool(logical_eq(has_offset, 1))) {

                current_statement_begin__ = 810;
                stan::math::assign(eta0, add(eta0, offset0));
                current_statement_begin__ = 811;
                stan::math::assign(eta1, add(eta1, offset1));
            }
            current_statement_begin__ = 813;
            if (as_bool(special_case)) {
                current_statement_begin__ = 813;
                for (int i = 1; i <= t; ++i) {

                    current_statement_begin__ = 814;
                    stan::math::assign(eta0, add(eta0, stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V0, i, "V0", 1)), stan::model::nil_index_list()), "b")));
                    current_statement_begin__ = 815;
                    stan::math::assign(eta1, add(eta1, stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V1, i, "V1", 1)), stan::model::nil_index_list()), "b")));
                }
            } else if (as_bool(logical_gt(t, 0))) {

                current_statement_begin__ = 818;
                stan::math::assign(eta0, add(eta0, csr_matrix_times_vector(get_base1(N, 1, "N", 1), q, w0, v0, u0, b)));
                current_statement_begin__ = 819;
                stan::math::assign(eta1, add(eta1, csr_matrix_times_vector(get_base1(N, 2, "N", 1), q, w1, v1, u1, b)));
            }
            current_statement_begin__ = 821;
            if (as_bool(logical_eq(has_intercept, 1))) {

                current_statement_begin__ = 822;
                if (as_bool(logical_neq(link, 4))) {

                    current_statement_begin__ = 823;
                    stan::math::assign(eta0, add(get_base1(gamma, 1, "gamma", 1), eta0));
                    current_statement_begin__ = 824;
                    stan::math::assign(eta1, add(get_base1(gamma, 1, "gamma", 1), eta1));
                } else {
                    {
                    current_statement_begin__ = 827;
                    local_scalar_t__ shift(DUMMY_VAR__);
                    (void) shift;  // dummy to suppress unused var warning
                    stan::math::initialize(shift, DUMMY_VAR__);
                    stan::math::fill(shift, DUMMY_VAR__);
                    stan::math::assign(shift,stan::math::fmax(max(eta0), max(eta1)));


                    current_statement_begin__ = 828;
                    stan::math::assign(eta0, subtract(add(get_base1(gamma, 1, "gamma", 1), eta0), shift));
                    current_statement_begin__ = 829;
                    stan::math::assign(eta1, subtract(add(get_base1(gamma, 1, "gamma", 1), eta1), shift));
                    }
                }
            }
            current_statement_begin__ = 832;
            if (as_bool(logical_eq(has_weights, 0))) {
                {
                current_statement_begin__ = 833;
                local_scalar_t__ dummy(DUMMY_VAR__);
                (void) dummy;  // dummy to suppress unused var warning
                stan::math::initialize(dummy, DUMMY_VAR__);
                stan::math::fill(dummy, DUMMY_VAR__);
                stan::math::assign(dummy,ll_bern_lp(eta0, eta1, link, N, lp__, lp_accum__, pstream__));


                }
            } else {

                current_statement_begin__ = 836;
                lp_accum__.add(dot_product(weights0, pw_bern(0, eta0, link, pstream__)));
                current_statement_begin__ = 837;
                lp_accum__.add(dot_product(weights1, pw_bern(1, eta1, link, pstream__)));
            }
            current_statement_begin__ = 841;
            if (as_bool(logical_eq(prior_dist, 1))) {
                current_statement_begin__ = 841;
                lp_accum__.add(normal_log(z_delta, 0, 1));
            } else if (as_bool(logical_eq(prior_dist, 2))) {
                current_statement_begin__ = 842;
                lp_accum__.add(normal_log(z_delta, 0, 1));
            } else if (as_bool(logical_eq(prior_dist, 5))) {

                current_statement_begin__ = 844;
                lp_accum__.add(normal_log(z_delta, 0, 1));
                current_statement_begin__ = 845;
                lp_accum__.add(exponential_log(get_base1(mix, 1, "mix", 1), 1));
            } else if (as_bool(logical_eq(prior_dist, 6))) {

                current_statement_begin__ = 848;
                lp_accum__.add(normal_log(z_delta, 0, 1));
                current_statement_begin__ = 849;
                lp_accum__.add(exponential_log(get_base1(mix, 1, "mix", 1), 1));
                current_statement_begin__ = 850;
                lp_accum__.add(chi_square_log(get_base1(one_over_lambda, 1, "one_over_lambda", 1), get_base1(prior_df, 1, "prior_df", 1)));
            } else if (as_bool(logical_eq(prior_dist, 7))) {

                current_statement_begin__ = 853;
                lp_accum__.add(normal_log(z_delta, 0, 1));
            }
            current_statement_begin__ = 858;
            if (as_bool(logical_eq(has_intercept, 1))) {

                current_statement_begin__ = 859;
                if (as_bool(logical_eq(prior_dist_for_intercept, 1))) {
                    current_statement_begin__ = 860;
                    lp_accum__.add(normal_log(gamma, prior_mean_for_intercept, prior_scale_for_intercept));
                } else if (as_bool(logical_eq(prior_dist_for_intercept, 2))) {
                    current_statement_begin__ = 862;
                    lp_accum__.add(student_t_log(gamma, prior_df_for_intercept, prior_mean_for_intercept, prior_scale_for_intercept));
                }
            }
            current_statement_begin__ = 868;
            if (as_bool(logical_eq(prior_dist_for_stap, 1))) {
                current_statement_begin__ = 868;
                lp_accum__.add(normal_log(z_beta, 0, 1));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 2))) {
                current_statement_begin__ = 869;
                lp_accum__.add(normal_log(z_beta, 0, 1));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 5))) {

                current_statement_begin__ = 871;
                lp_accum__.add(normal_log(z_beta, 0, 1));
                current_statement_begin__ = 872;
                lp_accum__.add(exponential_log(get_base1(mix_stap, 1, "mix_stap", 1), 1));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 6))) {

                current_statement_begin__ = 875;
                lp_accum__.add(normal_log(z_beta, 0, 1));
                current_statement_begin__ = 876;
                lp_accum__.add(exponential_log(get_base1(mix_stap, 1, "mix_stap", 1), 1));
                current_statement_begin__ = 877;
                lp_accum__.add(chi_square_log(get_base1(one_over_lambda_stap, 1, "one_over_lambda_stap", 1), get_base1(prior_df, 1, "prior_df", 1)));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 7))) {

                current_statement_begin__ = 880;
                lp_accum__.add(normal_log(z_beta, 0, 1));
            }
            {
            current_statement_begin__ = 886;
            int cnt_s(0);
            (void) cnt_s;  // dummy to suppress unused var warning
            stan::math::fill(cnt_s, std::numeric_limits<int>::min());
            stan::math::assign(cnt_s,1);

            current_statement_begin__ = 887;
            int cnt_t(0);
            (void) cnt_t;  // dummy to suppress unused var warning
            stan::math::fill(cnt_t, std::numeric_limits<int>::min());
            stan::math::assign(cnt_t,1);

            current_statement_begin__ = 888;
            int cnt_shape_s(0);
            (void) cnt_shape_s;  // dummy to suppress unused var warning
            stan::math::fill(cnt_shape_s, std::numeric_limits<int>::min());
            stan::math::assign(cnt_shape_s,1);

            current_statement_begin__ = 889;
            int cnt_shape_t(0);
            (void) cnt_shape_t;  // dummy to suppress unused var warning
            stan::math::fill(cnt_shape_t, std::numeric_limits<int>::min());
            stan::math::assign(cnt_shape_t,1);


            current_statement_begin__ = 890;
            for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                current_statement_begin__ = 891;
                if (as_bool((primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 0)) || primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 2))))) {

                    current_statement_begin__ = 892;
                    if (as_bool(logical_eq(get_base1(prior_dist_for_theta_s, cnt_s, "prior_dist_for_theta_s", 1), 1))) {

                        current_statement_begin__ = 893;
                        lp_accum__.add(normal_log(get_base1(theta_s, cnt_s, "theta_s", 1), get_base1(prior_mean_for_theta_s, cnt_s, "prior_mean_for_theta_s", 1), get_base1(prior_scale_for_theta_s, cnt_s, "prior_scale_for_theta_s", 1)));
                        current_statement_begin__ = 894;
                        if (as_bool((primitive_value(logical_gt(num_s_wei, 0)) && primitive_value(logical_gt(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), 4))))) {

                            current_statement_begin__ = 895;
                            lp_accum__.add(normal_log(get_base1(shape_s, cnt_shape_s, "shape_s", 1), get_base1(prior_mean_for_theta_s, cnt_s, "prior_mean_for_theta_s", 1), get_base1(prior_scale_for_theta_s, cnt_s, "prior_scale_for_theta_s", 1)));
                            current_statement_begin__ = 896;
                            stan::math::assign(cnt_shape_s, (cnt_shape_s + 1));
                        }
                    } else if (as_bool(logical_eq(get_base1(prior_dist_for_theta_s, cnt_s, "prior_dist_for_theta_s", 1), 8))) {

                        current_statement_begin__ = 900;
                        lp_accum__.add(lognormal_log(get_base1(theta_s, cnt_s, "theta_s", 1), get_base1(prior_mean_for_theta_s, cnt_s, "prior_mean_for_theta_s", 1), get_base1(prior_scale_for_theta_s, cnt_s, "prior_scale_for_theta_s", 1)));
                        current_statement_begin__ = 901;
                        if (as_bool((primitive_value(logical_gt(num_s_wei, 0)) && primitive_value(logical_gt(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), 4))))) {

                            current_statement_begin__ = 902;
                            lp_accum__.add(lognormal_log(get_base1(shape_s, cnt_shape_s, "shape_s", 1), get_base1(prior_mean_for_theta_s, cnt_s, "prior_mean_for_theta_s", 1), get_base1(prior_scale_for_theta_s, cnt_s, "prior_scale_for_theta_s", 1)));
                            current_statement_begin__ = 903;
                            stan::math::assign(cnt_shape_s, (cnt_shape_s + 1));
                        }
                    }
                    current_statement_begin__ = 906;
                    stan::math::assign(cnt_s, (cnt_s + 1));
                }
                current_statement_begin__ = 908;
                if (as_bool((primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 1)) || primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 2))))) {

                    current_statement_begin__ = 909;
                    if (as_bool(logical_eq(get_base1(prior_dist_for_theta_t, cnt_t, "prior_dist_for_theta_t", 1), 1))) {

                        current_statement_begin__ = 910;
                        lp_accum__.add(normal_log(get_base1(theta_t, cnt_t, "theta_t", 1), get_base1(prior_mean_for_theta_t, cnt_t, "prior_mean_for_theta_t", 1), get_base1(prior_scale_for_theta_t, cnt_t, "prior_scale_for_theta_t", 1)));
                        current_statement_begin__ = 911;
                        if (as_bool((primitive_value(logical_gt(num_t_wei, 0)) && primitive_value(logical_eq(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), 6))))) {

                            current_statement_begin__ = 912;
                            lp_accum__.add(normal_log(get_base1(shape_s, cnt_shape_t, "shape_s", 1), get_base1(prior_mean_for_theta_s, cnt_t, "prior_mean_for_theta_s", 1), get_base1(prior_scale_for_theta_t, cnt_t, "prior_scale_for_theta_t", 1)));
                            current_statement_begin__ = 913;
                            stan::math::assign(cnt_shape_t, (cnt_shape_t + 1));
                        }
                    }
                    current_statement_begin__ = 916;
                    if (as_bool(logical_eq(get_base1(prior_dist_for_theta_t, cnt_t, "prior_dist_for_theta_t", 1), 8))) {

                        current_statement_begin__ = 917;
                        lp_accum__.add(lognormal_log(get_base1(theta_t, cnt_t, "theta_t", 1), get_base1(prior_mean_for_theta_t, cnt_t, "prior_mean_for_theta_t", 1), get_base1(prior_scale_for_theta_t, cnt_t, "prior_scale_for_theta_t", 1)));
                        current_statement_begin__ = 918;
                        if (as_bool((primitive_value(logical_gt(num_t_wei, 0)) && primitive_value(logical_eq(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), 6))))) {

                            current_statement_begin__ = 919;
                            lp_accum__.add(lognormal_log(get_base1(shape_t, cnt_shape_t, "shape_t", 1), get_base1(prior_mean_for_theta_t, cnt_t, "prior_mean_for_theta_t", 1), get_base1(prior_scale_for_theta_t, cnt_t, "prior_scale_for_theta_t", 1)));
                            current_statement_begin__ = 920;
                            stan::math::assign(cnt_shape_t, (cnt_shape_t + 1));
                        }
                    }
                    current_statement_begin__ = 923;
                    stan::math::assign(cnt_t, (cnt_t + 1));
                }
            }
            }
            current_statement_begin__ = 928;
            if (as_bool(logical_gt(t, 0))) {
                current_statement_begin__ = 928;
                decov_lp(z_b, z_T, rho, zeta, tau, regularization, del, shape, t, p, lp__, lp_accum__, pstream__);
            }
            }

        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_delta");
        names__.push_back("mix");
        names__.push_back("z_beta");
        names__.push_back("mix_stap");
        names__.push_back("one_over_lambda");
        names__.push_back("one_over_lambda_stap");
        names__.push_back("theta_s");
        names__.push_back("shape_s");
        names__.push_back("shape_t");
        names__.push_back("theta_t");
        names__.push_back("z_b");
        names__.push_back("z_T");
        names__.push_back("rho");
        names__.push_back("zeta");
        names__.push_back("tau");
        names__.push_back("delta");
        names__.push_back("beta");
        names__.push_back("X");
        names__.push_back("X_tilde");
        names__.push_back("b");
        names__.push_back("theta_L");
        names__.push_back("alpha");
        names__.push_back("adj_beta");
        names__.push_back("mean_PPD");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6))));
        dims__.push_back(Q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist, 6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist_for_stap, 6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((Q_s + Q_st));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(num_s_wei);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(num_t_wei);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((Q_t + Q_st));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_z_T);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_rho);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_concentration);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(t);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(Q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(NN);
        dims__.push_back(Q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(NN);
        dims__.push_back(Q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_theta_L);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(Q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        typedef double local_scalar_t__;

        vars__.resize(0);
        stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
        static const char* function__ = "model_stap_bernoulli_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning

        // read-transform, write parameters
        std::vector<double> gamma;
        size_t gamma_d_0_max__ = has_intercept;
        gamma.reserve(gamma_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < gamma_d_0_max__; ++d_0__) {
            gamma.push_back(in__.scalar_ub_constrain((logical_eq(link, 4) ? 0.0 : stan::math::positive_infinity() )));
        }
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_delta = in__.vector_constrain((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        size_t z_delta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_delta_j_1_max__; ++j_1__) {
            vars__.push_back(z_delta(j_1__));
        }

        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mix;
        size_t mix_d_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        mix.reserve(mix_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < mix_d_0_max__; ++d_0__) {
            mix.push_back(in__.vector_lb_constrain(0, K));
        }
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                vars__.push_back(mix[k_0__](j_1__));
            }
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_beta = in__.vector_constrain((logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q ));
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            vars__.push_back(z_beta(j_1__));
        }

        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mix_stap;
        size_t mix_stap_d_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
        mix_stap.reserve(mix_stap_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < mix_stap_d_0_max__; ++d_0__) {
            mix_stap.push_back(in__.vector_lb_constrain(0, Q));
        }
        size_t mix_stap_j_1_max__ = Q;
        size_t mix_stap_k_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_stap_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_stap_k_0_max__; ++k_0__) {
                vars__.push_back(mix_stap[k_0__](j_1__));
            }
        }

        std::vector<double> one_over_lambda;
        size_t one_over_lambda_d_0_max__ = logical_eq(prior_dist, 6);
        one_over_lambda.reserve(one_over_lambda_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < one_over_lambda_d_0_max__; ++d_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }

        std::vector<double> one_over_lambda_stap;
        size_t one_over_lambda_stap_d_0_max__ = logical_eq(prior_dist_for_stap, 6);
        one_over_lambda_stap.reserve(one_over_lambda_stap_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < one_over_lambda_stap_d_0_max__; ++d_0__) {
            one_over_lambda_stap.push_back(in__.scalar_lb_constrain(0));
        }
        size_t one_over_lambda_stap_k_0_max__ = logical_eq(prior_dist_for_stap, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_stap_k_0_max__; ++k_0__) {
            vars__.push_back(one_over_lambda_stap[k_0__]);
        }

        std::vector<double> theta_s;
        size_t theta_s_d_0_max__ = (Q_s + Q_st);
        theta_s.reserve(theta_s_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < theta_s_d_0_max__; ++d_0__) {
            theta_s.push_back(in__.scalar_lub_constrain(0, max_distance));
        }
        size_t theta_s_k_0_max__ = (Q_s + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_s_k_0_max__; ++k_0__) {
            vars__.push_back(theta_s[k_0__]);
        }

        std::vector<double> shape_s;
        size_t shape_s_d_0_max__ = num_s_wei;
        shape_s.reserve(shape_s_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < shape_s_d_0_max__; ++d_0__) {
            shape_s.push_back(in__.scalar_lb_constrain(0));
        }
        size_t shape_s_k_0_max__ = num_s_wei;
        for (size_t k_0__ = 0; k_0__ < shape_s_k_0_max__; ++k_0__) {
            vars__.push_back(shape_s[k_0__]);
        }

        std::vector<double> shape_t;
        size_t shape_t_d_0_max__ = num_t_wei;
        shape_t.reserve(shape_t_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < shape_t_d_0_max__; ++d_0__) {
            shape_t.push_back(in__.scalar_lb_constrain(0));
        }
        size_t shape_t_k_0_max__ = num_t_wei;
        for (size_t k_0__ = 0; k_0__ < shape_t_k_0_max__; ++k_0__) {
            vars__.push_back(shape_t[k_0__]);
        }

        std::vector<double> theta_t;
        size_t theta_t_d_0_max__ = (Q_t + Q_st);
        theta_t.reserve(theta_t_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < theta_t_d_0_max__; ++d_0__) {
            theta_t.push_back(in__.scalar_lub_constrain(0, max_time));
        }
        size_t theta_t_k_0_max__ = (Q_t + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_t_k_0_max__; ++k_0__) {
            vars__.push_back(theta_t[k_0__]);
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_b = in__.vector_constrain(q);
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            vars__.push_back(z_b(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_T = in__.vector_constrain(len_z_T);
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            vars__.push_back(z_T(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> rho = in__.vector_lub_constrain(0, 1, len_rho);
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            vars__.push_back(rho(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> zeta = in__.vector_lb_constrain(0, len_concentration);
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            vars__.push_back(zeta(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> tau = in__.vector_lb_constrain(0, t);
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            vars__.push_back(tau(j_1__));
        }

        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        if (!include_tparams__ && !include_gqs__) return;

        try {
            // declare and define transformed parameters
            current_statement_begin__ = 692;
            validate_non_negative_index("delta", "K", K);
            Eigen::Matrix<double, Eigen::Dynamic, 1> delta(K);
            stan::math::initialize(delta, DUMMY_VAR__);
            stan::math::fill(delta, DUMMY_VAR__);

            current_statement_begin__ = 693;
            validate_non_negative_index("beta", "Q", Q);
            Eigen::Matrix<double, Eigen::Dynamic, 1> beta(Q);
            stan::math::initialize(beta, DUMMY_VAR__);
            stan::math::fill(beta, DUMMY_VAR__);

            current_statement_begin__ = 694;
            validate_non_negative_index("X", "NN", NN);
            validate_non_negative_index("X", "Q", Q);
            Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> X(NN, Q);
            stan::math::initialize(X, DUMMY_VAR__);
            stan::math::fill(X, DUMMY_VAR__);

            current_statement_begin__ = 695;
            validate_non_negative_index("X_tilde", "NN", NN);
            validate_non_negative_index("X_tilde", "Q", Q);
            Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic> X_tilde(NN, Q);
            stan::math::initialize(X_tilde, DUMMY_VAR__);
            stan::math::fill(X_tilde, DUMMY_VAR__);

            current_statement_begin__ = 696;
            validate_non_negative_index("b", "q", q);
            Eigen::Matrix<double, Eigen::Dynamic, 1> b(q);
            stan::math::initialize(b, DUMMY_VAR__);
            stan::math::fill(b, DUMMY_VAR__);

            current_statement_begin__ = 697;
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<double, Eigen::Dynamic, 1> theta_L(len_theta_L);
            stan::math::initialize(theta_L, DUMMY_VAR__);
            stan::math::fill(theta_L, DUMMY_VAR__);

            // do transformed parameters statements
            {
            current_statement_begin__ = 701;
            int cnt_s(0);
            (void) cnt_s;  // dummy to suppress unused var warning
            stan::math::fill(cnt_s, std::numeric_limits<int>::min());
            stan::math::assign(cnt_s,1);

            current_statement_begin__ = 702;
            int cnt_t(0);
            (void) cnt_t;  // dummy to suppress unused var warning
            stan::math::fill(cnt_t, std::numeric_limits<int>::min());
            stan::math::assign(cnt_t,1);

            current_statement_begin__ = 703;
            int cnt_shape_s(0);
            (void) cnt_shape_s;  // dummy to suppress unused var warning
            stan::math::fill(cnt_shape_s, std::numeric_limits<int>::min());
            stan::math::assign(cnt_shape_s,1);

            current_statement_begin__ = 704;
            int cnt_shape_t(0);
            (void) cnt_shape_t;  // dummy to suppress unused var warning
            stan::math::fill(cnt_shape_t, std::numeric_limits<int>::min());
            stan::math::assign(cnt_shape_t,1);


            current_statement_begin__ = 705;
            for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                current_statement_begin__ = 706;
                for (int n = 1; n <= NN; ++n) {

                    current_statement_begin__ = 707;
                    if (as_bool(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 0))) {
                        current_statement_begin__ = 708;
                        stan::model::assign(X, 
                                    stan::model::cons_list(stan::model::index_uni(n), stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list())), 
                                    assign_exposure(get_base1(log_ar, q_ix, "log_ar", 1), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), u_s, get_base1(dists_crs, cnt_s, "dists_crs", 1), get_base1(theta_s, cnt_s, "theta_s", 1), shape_s, cnt_shape_s, q_ix, n, pstream__), 
                                    "assigning variable X");
                    } else if (as_bool(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 1))) {
                        current_statement_begin__ = 710;
                        stan::model::assign(X, 
                                    stan::model::cons_list(stan::model::index_uni(n), stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list())), 
                                    assign_exposure(get_base1(log_ar, q_ix, "log_ar", 1), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), u_t, get_base1(times_crs, cnt_t, "times_crs", 1), get_base1(theta_t, cnt_t, "theta_t", 1), shape_t, cnt_shape_t, q_ix, n, pstream__), 
                                    "assigning variable X");
                    } else {
                        current_statement_begin__ = 712;
                        stan::model::assign(X, 
                                    stan::model::cons_list(stan::model::index_uni(n), stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list())), 
                                    assign_st_exposure(get_base1(log_ar, q_ix, "log_ar", 1), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), u_s, u_t, get_base1(dists_crs, cnt_s, "dists_crs", 1), get_base1(times_crs, cnt_t, "times_crs", 1), get_base1(theta_s, cnt_s, "theta_s", 1), get_base1(theta_t, cnt_t, "theta_t", 1), shape_s, shape_t, cnt_shape_s, cnt_shape_t, q_ix, n, pstream__), 
                                    "assigning variable X");
                    }
                }
                current_statement_begin__ = 714;
                if (as_bool((primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 0)) || primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 2))))) {

                    current_statement_begin__ = 715;
                    stan::math::assign(cnt_s, (cnt_s + 1));
                    current_statement_begin__ = 716;
                    stan::math::assign(cnt_shape_s, (cnt_shape_s + (logical_eq(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 1, "weight_mat", 2), 5) ? 1 : 0 )));
                }
                current_statement_begin__ = 718;
                if (as_bool((primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 1)) || primitive_value(logical_eq(get_base1(stap_code, q_ix, "stap_code", 1), 2))))) {

                    current_statement_begin__ = 719;
                    stan::math::assign(cnt_t, (cnt_t + 1));
                    current_statement_begin__ = 720;
                    stan::math::assign(cnt_shape_t, (cnt_shape_t + (logical_eq(get_base1(get_base1(weight_mat, q_ix, "weight_mat", 1), 2, "weight_mat", 2), 6) ? 1 : 0 )));
                }
            }
            }
            current_statement_begin__ = 725;
            stan::math::assign(X_tilde, centerscale(X, pstream__));
            current_statement_begin__ = 728;
            if (as_bool(logical_eq(prior_dist, 0))) {
                current_statement_begin__ = 728;
                stan::math::assign(delta, z_delta);
            } else if (as_bool(logical_eq(prior_dist, 1))) {
                current_statement_begin__ = 729;
                stan::math::assign(delta, add(elt_multiply(z_delta, prior_scale), prior_mean));
            } else if (as_bool(logical_eq(prior_dist, 2))) {

                current_statement_begin__ = 731;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 732;
                    stan::model::assign(delta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                ((CFt(get_base1(z_delta, k, "z_delta", 1), get_base1(prior_df, k, "prior_df", 1), pstream__) * get_base1(prior_scale, k, "prior_scale", 1)) + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable delta");
                }
            } else if (as_bool(logical_eq(prior_dist, 5))) {
                current_statement_begin__ = 736;
                stan::math::assign(delta, add(prior_mean, elt_multiply(elt_multiply(prior_scale, stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_delta)));
            } else if (as_bool(logical_eq(prior_dist, 6))) {
                current_statement_begin__ = 738;
                stan::math::assign(delta, add(prior_mean, elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda, 1, "one_over_lambda", 1), prior_scale), stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_delta)));
            } else if (as_bool(logical_eq(prior_dist, 7))) {
                {
                current_statement_begin__ = 740;
                int z_pos(0);
                (void) z_pos;  // dummy to suppress unused var warning
                stan::math::fill(z_pos, std::numeric_limits<int>::min());
                stan::math::assign(z_pos,1);


                current_statement_begin__ = 741;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 742;
                    stan::model::assign(delta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                get_base1(z_delta, z_pos, "z_delta", 1), 
                                "assigning variable delta");
                    current_statement_begin__ = 743;
                    stan::math::assign(z_pos, (z_pos + 1));
                    current_statement_begin__ = 744;
                    for (int n = 2; n <= get_base1(num_normals, k, "num_normals", 1); ++n) {

                        current_statement_begin__ = 745;
                        stan::model::assign(delta, 
                                    stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                    (get_base1(delta, k, "delta", 1) * get_base1(z_delta, z_pos, "z_delta", 1)), 
                                    "assigning variable delta");
                        current_statement_begin__ = 746;
                        stan::math::assign(z_pos, (z_pos + 1));
                    }
                    current_statement_begin__ = 748;
                    stan::model::assign(delta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                ((get_base1(delta, k, "delta", 1) * pow(get_base1(prior_scale, k, "prior_scale", 1), get_base1(num_normals, k, "num_normals", 1))) + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable delta");
                }
                }
            }
            current_statement_begin__ = 753;
            if (as_bool(logical_eq(prior_dist_for_stap, 0))) {
                current_statement_begin__ = 753;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist_for_stap, 1))) {
                current_statement_begin__ = 754;
                stan::math::assign(beta, add(elt_multiply(z_beta, prior_scale_for_stap), prior_mean_for_stap));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 2))) {
                current_statement_begin__ = 755;
                for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                    current_statement_begin__ = 756;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                ((CFt(get_base1(z_beta, q_ix, "z_beta", 1), get_base1(prior_df_for_stap, q_ix, "prior_df_for_stap", 1), pstream__) * get_base1(prior_scale_for_stap, q_ix, "prior_scale_for_stap", 1)) + get_base1(prior_mean_for_stap, q_ix, "prior_mean_for_stap", 1)), 
                                "assigning variable beta");
                }
            } else if (as_bool(logical_eq(prior_dist_for_stap, 5))) {
                current_statement_begin__ = 759;
                stan::math::assign(beta, add(prior_mean_for_stap, elt_multiply(elt_multiply(prior_scale_for_stap, stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 6))) {
                current_statement_begin__ = 761;
                stan::math::assign(beta, add(prior_mean_for_stap, elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda, 1, "one_over_lambda", 1), prior_scale_for_stap), stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist_for_stap, 7))) {
                {
                current_statement_begin__ = 763;
                int z_pos(0);
                (void) z_pos;  // dummy to suppress unused var warning
                stan::math::fill(z_pos, std::numeric_limits<int>::min());
                stan::math::assign(z_pos,1);


                current_statement_begin__ = 764;
                for (int q_ix = 1; q_ix <= Q; ++q_ix) {

                    current_statement_begin__ = 765;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                get_base1(z_beta, z_pos, "z_beta", 1), 
                                "assigning variable beta");
                    current_statement_begin__ = 766;
                    stan::math::assign(z_pos, (z_pos + 1));
                    current_statement_begin__ = 767;
                    for (int n = 2; n <= get_base1(num_normals_for_stap, q_ix, "num_normals_for_stap", 1); ++n) {

                        current_statement_begin__ = 768;
                        stan::model::assign(beta, 
                                    stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                    (get_base1(beta, q_ix, "beta", 1) * get_base1(z_delta, z_pos, "z_delta", 1)), 
                                    "assigning variable beta");
                        current_statement_begin__ = 769;
                        stan::math::assign(z_pos, (z_pos + 1));
                    }
                    current_statement_begin__ = 771;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(q_ix), stan::model::nil_index_list()), 
                                ((get_base1(delta, q_ix, "delta", 1) * pow(get_base1(prior_scale_for_stap, q_ix, "prior_scale_for_stap", 1), get_base1(num_normals_for_stap, q_ix, "num_normals_for_stap", 1))) + get_base1(prior_mean_for_stap, q_ix, "prior_mean_for_stap", 1)), 
                                "assigning variable beta");
                }
                }
            }
            current_statement_begin__ = 774;
            if (as_bool(logical_gt(t, 0))) {

                current_statement_begin__ = 775;
                if (as_bool(special_case)) {
                    {
                    current_statement_begin__ = 776;
                    int start(0);
                    (void) start;  // dummy to suppress unused var warning
                    stan::math::fill(start, std::numeric_limits<int>::min());
                    stan::math::assign(start,1);


                    current_statement_begin__ = 777;
                    stan::math::assign(theta_L, elt_multiply(scale, tau));
                    current_statement_begin__ = 778;
                    if (as_bool(logical_eq(t, 1))) {
                        current_statement_begin__ = 778;
                        stan::math::assign(b, multiply(get_base1(theta_L, 1, "theta_L", 1), z_b));
                    } else {
                        current_statement_begin__ = 779;
                        for (int i = 1; i <= t; ++i) {
                            {
                            current_statement_begin__ = 780;
                            int end(0);
                            (void) end;  // dummy to suppress unused var warning
                            stan::math::fill(end, std::numeric_limits<int>::min());
                            stan::math::assign(end,((start + get_base1(l, i, "l", 1)) - 1));


                            current_statement_begin__ = 781;
                            stan::model::assign(b, 
                                        stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), 
                                        multiply(get_base1(theta_L, i, "theta_L", 1), stan::model::rvalue(z_b, stan::model::cons_list(stan::model::index_min_max(start, end), stan::model::nil_index_list()), "z_b")), 
                                        "assigning variable b");
                            current_statement_begin__ = 782;
                            stan::math::assign(start, (end + 1));
                            }
                        }
                    }
                    }
                } else {

                    current_statement_begin__ = 786;
                    stan::math::assign(theta_L, make_theta_L(len_theta_L, p, 1.0, tau, scale, zeta, rho, z_T, pstream__));
                    current_statement_begin__ = 788;
                    stan::math::assign(b, make_b(z_b, theta_L, p, l, pstream__));
                }
            }

            if (!include_gqs__ && !include_tparams__) return;
            // validate transformed parameters
            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning

            // write transformed parameters
            if (include_tparams__) {
                size_t delta_j_1_max__ = K;
                for (size_t j_1__ = 0; j_1__ < delta_j_1_max__; ++j_1__) {
                    vars__.push_back(delta(j_1__));
                }
                size_t beta_j_1_max__ = Q;
                for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                    vars__.push_back(beta(j_1__));
                }
                size_t X_j_2_max__ = Q;
                size_t X_j_1_max__ = NN;
                for (size_t j_2__ = 0; j_2__ < X_j_2_max__; ++j_2__) {
                    for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                        vars__.push_back(X(j_1__, j_2__));
                    }
                }
                size_t X_tilde_j_2_max__ = Q;
                size_t X_tilde_j_1_max__ = NN;
                for (size_t j_2__ = 0; j_2__ < X_tilde_j_2_max__; ++j_2__) {
                    for (size_t j_1__ = 0; j_1__ < X_tilde_j_1_max__; ++j_1__) {
                        vars__.push_back(X_tilde(j_1__, j_2__));
                    }
                }
                size_t b_j_1_max__ = q;
                for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                    vars__.push_back(b(j_1__));
                }
                size_t theta_L_j_1_max__ = len_theta_L;
                for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                    vars__.push_back(theta_L(j_1__));
                }
            }
            if (!include_gqs__) return;
            // declare and define generated quantities
            current_statement_begin__ = 932;
            validate_non_negative_index("alpha", "has_intercept", has_intercept);
            std::vector<double> alpha(has_intercept, double(0));
            stan::math::initialize(alpha, DUMMY_VAR__);
            stan::math::fill(alpha, DUMMY_VAR__);

            current_statement_begin__ = 933;
            validate_non_negative_index("adj_beta", "Q", Q);
            Eigen::Matrix<double, Eigen::Dynamic, 1> adj_beta(Q);
            stan::math::initialize(adj_beta, DUMMY_VAR__);
            stan::math::fill(adj_beta, DUMMY_VAR__);

            current_statement_begin__ = 934;
            double mean_PPD;
            (void) mean_PPD;  // dummy to suppress unused var warning
            stan::math::initialize(mean_PPD, DUMMY_VAR__);
            stan::math::fill(mean_PPD, DUMMY_VAR__);
            stan::math::assign(mean_PPD,0);

            // generated quantities statements
            current_statement_begin__ = 935;
            if (as_bool(logical_eq(has_intercept, 1))) {

                current_statement_begin__ = 936;
                stan::model::assign(alpha, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            ((get_base1(gamma, 1, "gamma", 1) - dot_product(zbar, delta)) - dot_product(colmeans(X, pstream__), elt_divide(beta, colsds(X, pstream__)))), 
                            "assigning variable alpha");
            }
            {
            current_statement_begin__ = 939;
            validate_non_negative_index("pi0", "get_base1(N, 1, \"N\", 1)", get_base1(N, 1, "N", 1));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> pi0(get_base1(N, 1, "N", 1));
            stan::math::initialize(pi0, DUMMY_VAR__);
            stan::math::fill(pi0, DUMMY_VAR__);

            current_statement_begin__ = 940;
            validate_non_negative_index("pi1", "get_base1(N, 2, \"N\", 1)", get_base1(N, 2, "N", 1));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> pi1(get_base1(N, 2, "N", 1));
            stan::math::initialize(pi1, DUMMY_VAR__);
            stan::math::fill(pi1, DUMMY_VAR__);

            current_statement_begin__ = 943;
            validate_non_negative_index("eta0", "get_base1(N, 1, \"N\", 1)", get_base1(N, 1, "N", 1));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta0(get_base1(N, 1, "N", 1));
            stan::math::initialize(eta0, DUMMY_VAR__);
            stan::math::fill(eta0, DUMMY_VAR__);

            current_statement_begin__ = 944;
            validate_non_negative_index("eta1", "get_base1(N, 2, \"N\", 1)", get_base1(N, 2, "N", 1));
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta1(get_base1(N, 2, "N", 1));
            stan::math::initialize(eta1, DUMMY_VAR__);
            stan::math::fill(eta1, DUMMY_VAR__);


            current_statement_begin__ = 945;
            stan::math::assign(eta0, rep_vector(0.0, get_base1(N, 1, "N", 1)));
            current_statement_begin__ = 946;
            stan::math::assign(eta1, rep_vector(0.0, get_base1(N, 2, "N", 1)));
            current_statement_begin__ = 948;
            if (as_bool(logical_eq(has_intercept, 0))) {
                {
                current_statement_begin__ = 949;
                local_scalar_t__ tmp(DUMMY_VAR__);
                (void) tmp;  // dummy to suppress unused var warning
                stan::math::initialize(tmp, DUMMY_VAR__);
                stan::math::fill(tmp, DUMMY_VAR__);


                current_statement_begin__ = 950;
                stan::math::assign(tmp, dot_product(zbar, delta));
                current_statement_begin__ = 951;
                stan::math::assign(eta0, add(eta0, tmp));
                current_statement_begin__ = 952;
                stan::math::assign(eta1, add(eta1, tmp));
                }
            } else {

                current_statement_begin__ = 954;
                stan::math::assign(eta0, add(add(eta0, multiply(Z0, delta)), multiply(stan::model::rvalue(X_tilde, stan::model::cons_list(stan::model::index_multi(y_0), stan::model::cons_list(stan::model::index_omni(), stan::model::nil_index_list())), "X_tilde"), beta)));
                current_statement_begin__ = 955;
                stan::math::assign(eta1, add(add(eta1, multiply(Z1, delta)), multiply(stan::model::rvalue(X_tilde, stan::model::cons_list(stan::model::index_multi(y_1), stan::model::cons_list(stan::model::index_omni(), stan::model::nil_index_list())), "X_tilde"), beta)));
            }
            current_statement_begin__ = 957;
            if (as_bool(logical_eq(has_offset, 1))) {

                current_statement_begin__ = 958;
                stan::math::assign(eta0, add(eta0, offset0));
                current_statement_begin__ = 959;
                stan::math::assign(eta1, add(eta1, offset1));
            }
            current_statement_begin__ = 961;
            if (as_bool(special_case)) {
                current_statement_begin__ = 961;
                for (int i = 1; i <= t; ++i) {

                    current_statement_begin__ = 962;
                    stan::math::assign(eta0, add(eta0, stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V0, i, "V0", 1)), stan::model::nil_index_list()), "b")));
                    current_statement_begin__ = 963;
                    stan::math::assign(eta1, add(eta1, stan::model::rvalue(b, stan::model::cons_list(stan::model::index_multi(get_base1(V1, i, "V1", 1)), stan::model::nil_index_list()), "b")));
                }
            } else if (as_bool(logical_gt(t, 0))) {

                current_statement_begin__ = 966;
                stan::math::assign(eta0, add(eta0, csr_matrix_times_vector(get_base1(N, 1, "N", 1), q, w0, v0, u0, b)));
                current_statement_begin__ = 967;
                stan::math::assign(eta1, add(eta1, csr_matrix_times_vector(get_base1(N, 2, "N", 1), q, w1, v1, u1, b)));
            }
            current_statement_begin__ = 969;
            if (as_bool(logical_eq(has_intercept, 1))) {

                current_statement_begin__ = 970;
                if (as_bool(logical_neq(link, 4))) {

                    current_statement_begin__ = 971;
                    stan::math::assign(eta0, add(get_base1(gamma, 1, "gamma", 1), eta0));
                    current_statement_begin__ = 972;
                    stan::math::assign(eta1, add(get_base1(gamma, 1, "gamma", 1), eta1));
                } else {
                    {
                    current_statement_begin__ = 975;
                    local_scalar_t__ shift(DUMMY_VAR__);
                    (void) shift;  // dummy to suppress unused var warning
                    stan::math::initialize(shift, DUMMY_VAR__);
                    stan::math::fill(shift, DUMMY_VAR__);


                    current_statement_begin__ = 976;
                    stan::math::assign(shift, stan::math::fmax(max(eta0), max(eta1)));
                    current_statement_begin__ = 977;
                    stan::math::assign(eta0, subtract(add(get_base1(gamma, 1, "gamma", 1), eta0), shift));
                    current_statement_begin__ = 978;
                    stan::math::assign(eta1, subtract(add(get_base1(gamma, 1, "gamma", 1), eta1), shift));
                    current_statement_begin__ = 979;
                    stan::model::assign(alpha, 
                                stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                                (get_base1(alpha, 1, "alpha", 1) - shift), 
                                "assigning variable alpha");
                    }
                }
            }
            current_statement_begin__ = 983;
            stan::math::assign(pi0, linkinv_bern(eta0, link, pstream__));
            current_statement_begin__ = 984;
            stan::math::assign(pi1, linkinv_bern(eta1, link, pstream__));
            current_statement_begin__ = 985;
            for (int n = 1; n <= get_base1(N, 1, "N", 1); ++n) {
                current_statement_begin__ = 985;
                stan::math::assign(mean_PPD, (mean_PPD + bernoulli_rng(get_base1(pi0, n, "pi0", 1), base_rng__)));
            }
            current_statement_begin__ = 986;
            for (int n = 1; n <= get_base1(N, 2, "N", 1); ++n) {
                current_statement_begin__ = 986;
                stan::math::assign(mean_PPD, (mean_PPD + bernoulli_rng(get_base1(pi1, n, "pi1", 1), base_rng__)));
            }
            current_statement_begin__ = 988;
            stan::math::assign(mean_PPD, (mean_PPD / NN));
            current_statement_begin__ = 989;
            stan::math::assign(adj_beta, elt_divide(beta, colsds(X, pstream__)));
            }

            // validate, write generated quantities
            current_statement_begin__ = 932;
            size_t alpha_k_0_max__ = has_intercept;
            for (size_t k_0__ = 0; k_0__ < alpha_k_0_max__; ++k_0__) {
                vars__.push_back(alpha[k_0__]);
            }

            current_statement_begin__ = 933;
            size_t adj_beta_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < adj_beta_j_1_max__; ++j_1__) {
                vars__.push_back(adj_beta(j_1__));
            }

            current_statement_begin__ = 934;
            vars__.push_back(mean_PPD);

        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng, params_r_vec, params_i_vec, vars_vec, include_tparams, include_gqs, pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    static std::string model_name() {
        return "model_stap_bernoulli";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_delta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_delta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_delta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t mix_stap_j_1_max__ = Q;
        size_t mix_stap_k_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_stap_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_stap_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix_stap" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t one_over_lambda_stap_k_0_max__ = logical_eq(prior_dist_for_stap, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_stap_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda_stap" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_s_k_0_max__ = (Q_s + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_s_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_s" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t shape_s_k_0_max__ = num_s_wei;
        for (size_t k_0__ = 0; k_0__ < shape_s_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "shape_s" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t shape_t_k_0_max__ = num_t_wei;
        for (size_t k_0__ = 0; k_0__ < shape_t_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "shape_t" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_t_k_0_max__ = (Q_t + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_t_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_t" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;

        if (include_tparams__) {
            size_t delta_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < delta_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "delta" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t beta_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t X_j_2_max__ = Q;
            size_t X_j_1_max__ = NN;
            for (size_t j_2__ = 0; j_2__ < X_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "X" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
            size_t X_tilde_j_2_max__ = Q;
            size_t X_tilde_j_1_max__ = NN;
            for (size_t j_2__ = 0; j_2__ < X_tilde_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < X_tilde_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "X_tilde" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
            size_t b_j_1_max__ = q;
            for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "b" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t theta_L_j_1_max__ = len_theta_L;
            for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_L" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }

        if (!include_gqs__) return;
        size_t alpha_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < alpha_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t adj_beta_j_1_max__ = Q;
        for (size_t j_1__ = 0; j_1__ < adj_beta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "adj_beta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_delta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_delta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_delta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist_for_stap, 7) ? sum(num_normals) : Q );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t mix_stap_j_1_max__ = Q;
        size_t mix_stap_k_0_max__ = (primitive_value(logical_eq(prior_dist_for_stap, 5)) || primitive_value(logical_eq(prior_dist_for_stap, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_stap_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_stap_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix_stap" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t one_over_lambda_stap_k_0_max__ = logical_eq(prior_dist_for_stap, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_stap_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda_stap" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_s_k_0_max__ = (Q_s + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_s_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_s" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t shape_s_k_0_max__ = num_s_wei;
        for (size_t k_0__ = 0; k_0__ < shape_s_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "shape_s" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t shape_t_k_0_max__ = num_t_wei;
        for (size_t k_0__ = 0; k_0__ < shape_t_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "shape_t" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t theta_t_k_0_max__ = (Q_t + Q_st);
        for (size_t k_0__ = 0; k_0__ < theta_t_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "theta_t" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;

        if (include_tparams__) {
            size_t delta_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < delta_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "delta" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t beta_j_1_max__ = Q;
            for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t X_j_2_max__ = Q;
            size_t X_j_1_max__ = NN;
            for (size_t j_2__ = 0; j_2__ < X_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "X" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
            size_t X_tilde_j_2_max__ = Q;
            size_t X_tilde_j_1_max__ = NN;
            for (size_t j_2__ = 0; j_2__ < X_tilde_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < X_tilde_j_1_max__; ++j_1__) {
                    param_name_stream__.str(std::string());
                    param_name_stream__ << "X_tilde" << '.' << j_1__ + 1 << '.' << j_2__ + 1;
                    param_names__.push_back(param_name_stream__.str());
                }
            }
            size_t b_j_1_max__ = q;
            for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "b" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t theta_L_j_1_max__ = len_theta_L;
            for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_L" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }

        if (!include_gqs__) return;
        size_t alpha_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < alpha_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "alpha" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t adj_beta_j_1_max__ = Q;
        for (size_t j_1__ = 0; j_1__ < adj_beta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "adj_beta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "mean_PPD";
        param_names__.push_back(param_name_stream__.str());
    }

}; // model

}  // namespace

typedef model_stap_bernoulli_namespace::model_stap_bernoulli stan_model;


#endif
